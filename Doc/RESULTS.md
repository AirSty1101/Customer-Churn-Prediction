# Experiment Results - Customer Churn Prediction

‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏•‡∏≠‡∏á‡πÅ‡∏•‡∏∞ metrics ‡∏Ç‡∏≠‡∏á‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏£‡∏≠‡∏ö‡∏Å‡∏≤‡∏£ train model

---

## üìë Table of Contents

**Quick Links:**

- [üéØ ‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢ Metrics](#‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢-metrics)
- [üìä ‡∏™‡∏£‡∏∏‡∏õ‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö](#‡∏™‡∏£‡∏∏‡∏õ‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö)
- [üìù ‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡πÅ‡∏ï‡πà‡∏•‡∏∞ Run](#‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡πÅ‡∏ï‡πà‡∏•‡∏∞-run)
- [üí° ‡πÅ‡∏ô‡∏ß‡∏ó‡∏≤‡∏á‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á](#‡πÅ‡∏ô‡∏ß‡∏ó‡∏≤‡∏á‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á)
- [üéØ Next Steps](#next-immediate-steps)

---

## ‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢ Metrics

| Metric        | ‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢ | ‡πÄ‡∏´‡∏ï‡∏∏‡∏ú‡∏•                                   | ‡∏ú‡∏•‡∏Å‡∏£‡∏∞‡∏ó‡∏ö‡∏ó‡∏≤‡∏á‡∏ò‡∏∏‡∏£‡∏Å‡∏¥‡∏à                                                 |
| ------------- | -------- | ---------------------------------------- | ---------------------------------------------------------------- |
| **Recall**    | > 0.70   | ‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î - ‡∏ï‡πâ‡∏≠‡∏á‡∏à‡∏±‡∏ö Churn ‡πÑ‡∏î‡πâ‡∏°‡∏≤‡∏Å‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î | ‡∏à‡∏±‡∏ö‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤‡∏ó‡∏µ‡πà‡∏à‡∏∞ Churn ‡πÑ‡∏î‡πâ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ô‡πâ‡∏≠‡∏¢ 70% ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏°‡∏µ‡πÇ‡∏≠‡∏Å‡∏≤‡∏™‡∏£‡∏±‡∏Å‡∏©‡∏≤‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤‡πÑ‡∏ß‡πâ |
| **Precision** | > 0.60   | ‡∏•‡∏î False Positive                        | ‡∏•‡∏î‡∏ï‡πâ‡∏ô‡∏ó‡∏∏‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏¥‡∏î‡∏ï‡πà‡∏≠‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤‡∏ú‡∏¥‡∏î‡∏Ñ‡∏ô (‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ Churn ‡∏à‡∏£‡∏¥‡∏á)              |
| **F1 Score**  | > 0.65   | ‡∏™‡∏°‡∏î‡∏∏‡∏•‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á Precision & Recall          | ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏°‡∏î‡∏∏‡∏•‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏ö Churn ‡πÑ‡∏î‡πâ ‡πÅ‡∏•‡∏∞‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥                   |
| **ROC-AUC**   | > 0.80   | ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÅ‡∏¢‡∏Å class ‡πÇ‡∏î‡∏¢‡∏£‡∏ß‡∏°               | Model ‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÅ‡∏¢‡∏Å‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤ Churn/Not Churn ‡πÑ‡∏î‡πâ‡∏î‡∏µ                |

**‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏:** ‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏•‡πà‡∏≤‡∏ô‡∏µ‡πâ‡∏ï‡∏±‡πâ‡∏á‡∏Ç‡∏∂‡πâ‡∏ô‡∏à‡∏≤‡∏Å‡∏Å‡∏≤‡∏£‡∏û‡∏¥‡∏à‡∏≤‡∏£‡∏ì‡∏≤‡∏ß‡πà‡∏≤:

- **Recall ‡∏™‡∏π‡∏á** = ‡∏à‡∏±‡∏ö‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤‡∏ó‡∏µ‡πà‡∏à‡∏∞ Churn ‡πÑ‡∏î‡πâ‡∏°‡∏≤‡∏Å ‚Üí ‡∏•‡∏î‡∏Å‡∏≤‡∏£‡∏™‡∏π‡∏ç‡πÄ‡∏™‡∏µ‡∏¢‡∏£‡∏≤‡∏¢‡πÑ‡∏î‡πâ
- **Precision ‡∏û‡∏≠‡πÉ‡∏ä‡πâ** = ‡∏¢‡∏≠‡∏°‡∏£‡∏±‡∏ö False Positive ‡∏ö‡πâ‡∏≤‡∏á ‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡∏ï‡πâ‡∏ô‡∏ó‡∏∏‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏¥‡∏î‡∏ï‡πà‡∏≠‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤‡∏ï‡πà‡∏≥‡∏Å‡∏ß‡πà‡∏≤‡∏Å‡∏≤‡∏£‡∏™‡∏π‡∏ç‡πÄ‡∏™‡∏µ‡∏¢‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤
- **ROC-AUC > 0.80** = ‡πÄ‡∏õ‡πá‡∏ô‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô‡∏™‡∏≤‡∏Å‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö model ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÑ‡∏î‡πâ‡∏à‡∏£‡∏¥‡∏á

---

## ‡∏™‡∏£‡∏∏‡∏õ‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö

### Test Set Performance

**XGBoost Performance:**

| Run  | Model                                                       | XGB<br>Accuracy | XGB<br>Precision | XGB<br>Recall | XGB<br>F1  | XGB<br>ROC-AUC |
| ---- | ----------------------------------------------------------- | --------------- | ---------------- | ------------- | ---------- | -------------- |
| #1   | Baseline<br>(OneHot for both)                               | 0.6887          | 0.3501           | 0.6144        | 0.4460     | 0.7279         |
| #2   | Separate Preprocessing<br>(OneHot for LR, Label for XGB) ‚≠ê | 0.7880          | 0.4862           | 0.6895        | 0.5703     | 0.8379         |
| #2.1 | + Hyperparameter Tuning üöÄ                                  | 0.7793          | 0.4740           | 0.7451        | 0.5794     | **0.8461**     |
| #2.2 | + Threshold 0.54 üéØ                                         | 0.7933          | 0.4954           | 0.7026        | **0.5811** | **0.8461**     |
| #3   | SMOTE Resampling<br>(OneHot for LR, Label for XGB)          | 0.8020          | 0.5123           | 0.6144        | 0.5587     | 0.8170         |
| #4   | ADASYN Resampling<br>(OneHot for LR, Label for XGB)         | 0.7980          | 0.5041           | 0.6013        | 0.5484     | 0.8106         |
| #5   | SMOTETomek Resampling<br>(OneHot for LR, Label for XGB)     | **0.8033**      | **0.5153**       | 0.6046        | 0.5564     | 0.8121         |
| #6   | Cost-Sensitive Learning<br>(cost_ratio=10.0)                | 0.5107          | 0.2838           | **0.9183**    | 0.4336     | 0.8220         |

**Logistic Regression Performance:**

| Run  | Model                                                       | LR<br>Accuracy | LR<br>Precision | LR<br>Recall | LR<br>F1   | LR<br>ROC-AUC |
| ---- | ----------------------------------------------------------- | -------------- | --------------- | ------------ | ---------- | ------------- |
| #1   | Baseline<br>(OneHot for both)                               | **0.7147**     | **0.3887**      | **0.6961**   | **0.4988** | **0.7621**    |
| #2   | Separate Preprocessing<br>(OneHot for LR, Label for XGB) ‚≠ê | 0.7147         | 0.3887          | 0.6961       | 0.4988     | 0.7621        |
| #2.1 | + Hyperparameter Tuning üöÄ                                  | 0.7147         | 0.3887          | 0.6961       | 0.4988     | 0.7621        |
| #2.2 | + Threshold 0.54 üéØ                                         | 0.7147         | 0.3887          | 0.6961       | 0.4988     | 0.7621        |
| #3   | SMOTE Resampling<br>(OneHot for LR, Label for XGB)          | 0.6980         | 0.3708          | 0.6895       | 0.4823     | 0.7600        |
| #4   | ADASYN Resampling<br>(OneHot for LR, Label for XGB)         | 0.6927         | 0.3697          | 0.7190       | 0.4883     | 0.7617        |
| #5   | SMOTETomek Resampling<br>(OneHot for LR, Label for XGB)     | 0.6980         | 0.3708          | 0.6895       | 0.4823     | 0.7600        |
| #6   | Cost-Sensitive Learning<br>(cost_ratio=10.0)                | 0.7147         | 0.3887          | 0.6961       | 0.4988     | 0.7621        |

**Note:** LR ‡πÉ‡∏ä‡πâ class weights ‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏Å‡∏±‡∏ô‡πÉ‡∏ô‡∏ó‡∏∏‡∏Å runs (‡∏¢‡∏Å‡πÄ‡∏ß‡πâ‡∏ô synthetic sampling runs ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ SMOTE/ADASYN/SMOTETomek) ‡∏î‡∏±‡∏á‡∏ô‡∏±‡πâ‡∏ô performance ‡∏à‡∏∂‡∏á‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢‡∏Å‡∏±‡∏ô

### Key Takeaways

1. **üöÄ Run #2.1 (Hyperparameter Tuned) - Recall ‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î‡πÉ‡∏ô‡∏Å‡∏•‡∏∏‡πà‡∏° Non-Cost-Sensitive!** ü•á

   - **Recall = 74.51%** üéâ **‡πÄ‡∏Å‡∏¥‡∏ô‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢ 70% ‡πÅ‡∏•‡πâ‡∏ß!**
   - **ROC-AUC = 84.61%** ‚úÖ **‡πÄ‡∏Å‡∏¥‡∏ô‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢ 80%! (‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î)**
   - F1 = 0.5794 (‡∏î‡∏µ‡∏°‡∏≤‡∏Å!)
   - Precision = 0.4740 (‡∏û‡∏≠‡πÉ‡∏ä‡πâ‡πÑ‡∏î‡πâ)
   - **Recall ‡∏™‡∏π‡∏á‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡πÉ‡∏ô‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà Cost-Sensitive**
   - **Best Parameters:** n_estimators=50, max_depth=3, learning_rate=0.1, subsample=0.6

2. **üéØ Run #2.2 (+ Threshold 0.54) - Balance ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î!** ‚≠ê **MOST BALANCED**

   - **Recall = 70.26%** ‚úÖ **‡πÄ‡∏Å‡∏¥‡∏ô‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢ 70% ‡∏û‡∏≠‡∏î‡∏µ!**
   - **Precision = 49.54%** ‚úÖ **‡∏™‡∏π‡∏á‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡πÉ‡∏ô‡∏Å‡∏•‡∏∏‡πà‡∏° Recall >= 70%!**
   - **F1 = 58.11%** üèÜ **‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î!**
   - ROC-AUC = 84.61% ‚úÖ
   - Accuracy = 79.33% (‡∏î‡∏µ‡∏°‡∏≤‡∏Å!)
   - **Balance ‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á Precision & Recall ‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î!**

3. **Run #2 (Class Weights) - Baseline ‡∏ó‡∏µ‡πà‡∏î‡∏µ**

   - XGBoost: ROC-AUC = 0.8379, F1 = 0.5703, Recall = 0.6895
   - Balance ‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á Precision & Recall ‡∏î‡∏µ
   - ROI ‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î (5,668%)
   - ‚úÖ **‡πÄ‡∏Å‡∏¥‡∏ô‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢ ROC-AUC > 0.80 ‡πÅ‡∏•‡πâ‡∏ß!**

4. **Run #6 (Cost-Sensitive) ‡πÉ‡∏´‡πâ Recall ‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î‡πÇ‡∏î‡∏¢‡∏£‡∏ß‡∏°!** üöÄ

   - XGBoost: Recall = **0.9183** (‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î! +22.88 pp ‡∏à‡∏≤‡∏Å Run #2)
   - ‡∏à‡∏±‡∏ö‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤ Churn ‡πÑ‡∏î‡πâ 281/306 ‡∏Ñ‡∏ô (‡∏û‡∏•‡∏≤‡∏î‡πÅ‡∏Ñ‡πà 25 ‡∏Ñ‡∏ô!)
   - ‡πÅ‡∏ï‡πà Precision ‡∏ï‡πà‡∏≥‡∏°‡∏≤‡∏Å (0.2838) - ‡∏ï‡∏¥‡∏î‡∏ï‡πà‡∏≠‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤‡∏ú‡∏¥‡∏î‡∏Ñ‡∏ô‡∏°‡∏≤‡∏Å
   - ‡∏õ‡∏£‡∏∞‡∏´‡∏¢‡∏±‡∏î‡πÑ‡∏î‡πâ 16.3M ‡∏ö‡∏≤‡∏ó (‡∏°‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤ Run #2 ‡∏ñ‡∏∂‡∏á 3.76M ‡∏ö‡∏≤‡∏ó!)
   - **‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏Å‡∏±‡∏ö campaign ‡∏û‡∏¥‡πÄ‡∏®‡∏©‡∏ó‡∏µ‡πà‡∏¢‡∏≠‡∏°‡∏£‡∏±‡∏ö False Positive ‡∏™‡∏π‡∏á**

5. **‡∏ó‡∏î‡∏™‡∏≠‡∏ö Synthetic Sampling ‡∏Ñ‡∏£‡∏ö‡∏ó‡∏±‡πâ‡∏á 3 ‡∏ß‡∏¥‡∏ò‡∏µ‡πÅ‡∏•‡πâ‡∏ß:**

   - SMOTE (Run #3): ROC-AUC = 0.8170, Recall = 0.6144
   - SMOTETomek (Run #5): ROC-AUC = 0.8121, Recall = 0.6046, **Precision ‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î (0.5153)**
   - ADASYN (Run #4): ROC-AUC = 0.8106, Recall = 0.6013

6. **Synthetic Sampling ‡∏ó‡∏∏‡∏Å‡∏ß‡∏¥‡∏ò‡∏µ‡∏™‡∏£‡πâ‡∏≤‡∏á overfitting:**

   - Run #3: CV ROC-AUC = 0.91, Test = 0.82 (‡∏ï‡πà‡∏≤‡∏á‡∏Å‡∏±‡∏ô 9%)
   - Run #4: CV ROC-AUC = 0.91, Test = 0.81 (‡∏ï‡πà‡∏≤‡∏á‡∏Å‡∏±‡∏ô 10%)
   - Run #5: CV ROC-AUC = 0.91, Test = 0.81 (‡∏ï‡πà‡∏≤‡∏á‡∏Å‡∏±‡∏ô 10%)

7. **Recall Comparison:**

   - Run #6 (Cost-Sensitive): Recall = **91.83%** ü•á **(‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î‡πÇ‡∏î‡∏¢‡∏£‡∏ß‡∏°!)**
   - **Run #2.1 (Hyperparameter Tuned)**: Recall = **74.51%** ü•à **(‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î‡πÉ‡∏ô‡∏Å‡∏•‡∏∏‡πà‡∏° Non-CS!)**
   - **Run #2.2 (+ Threshold 0.54)**: Recall = **70.26%** ü•â **(Most Balanced!)**
   - Run #2 (Class Weights): Recall = 68.95%
   - Run #4 (ADASYN): Recall = 71.90%
   - Run #3 (SMOTE): Recall = 61.44%
   - Run #5 (SMOTETomek): Recall = 60.46%

   **Note:** Run #6 ‡∏°‡∏µ Recall ‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î ‡πÅ‡∏ï‡πà Precision ‡∏ï‡πà‡∏≥‡∏°‡∏≤‡∏Å (28.38%) ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏Å‡∏±‡∏ö campaign ‡∏û‡∏¥‡πÄ‡∏®‡∏©‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô

8. **Cost-Sensitive Learning Findings:**

   - Cost Ratio 20.0 ‡πÉ‡∏´‡πâ Recall ‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î (95.10%)
   - ‡∏¢‡∏¥‡πà‡∏á Cost Ratio ‡∏™‡∏π‡∏á ‚Üí Recall ‡πÄ‡∏û‡∏¥‡πà‡∏°, Precision ‡∏•‡∏î
   - ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏Å‡∏±‡∏ö‡∏ò‡∏ô‡∏≤‡∏Ñ‡∏≤‡∏£‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏ó‡∏µ‡∏° Retention ‡∏Ç‡∏ô‡∏≤‡∏î‡πÉ‡∏´‡∏ç‡πà

9. **‡πÅ‡∏¢‡∏Å preprocessing ‡∏ï‡∏≤‡∏° model** ‡∏ó‡∏≥‡πÉ‡∏´‡πâ XGBoost ‡∏î‡∏µ‡∏Ç‡∏∂‡πâ‡∏ô 15% ‡πÉ‡∏ô ROC-AUC (Run #1 ‚Üí Run #2)

10. **Hyperparameter Tuning = Big Win!** üöÄ
    - ‡πÄ‡∏û‡∏¥‡πà‡∏° Recall ‡∏à‡∏≤‡∏Å 68.95% ‚Üí 74.51% (+5.56 pp)
    - ‡πÄ‡∏û‡∏¥‡πà‡∏° ROC-AUC ‡∏à‡∏≤‡∏Å 83.79% ‚Üí 84.61% (+0.82 pp)
    - ‡πÑ‡∏î‡πâ‡∏ú‡∏•‡∏î‡∏µ‡∏Å‡∏ß‡πà‡∏≤ Threshold Tuning!

### Ranking Summary

| Rank | Run  | Method                  | ROC-AUC    | Recall     | Precision  | F1         | Overfitting? | Best For                    |
| ---- | ---- | ----------------------- | ---------- | ---------- | ---------- | ---------- | ------------ | --------------------------- |
| ü•á 1 | #2.2 | Hyperparameter + T=0.54 | **0.8461** | **0.7026** | **0.4954** | **0.5811** | ‚ùå No        | **Most Balanced** ‚≠ê        |
| ü•à 2 | #2.1 | Hyperparameter Tuned    | **0.8461** | **0.7451** | 0.4740     | 0.5794     | ‚ùå No        | **High Recall (Non-CS)** üöÄ |
| ü•â 3 | #2   | Class Weights           | 0.8379     | 0.6895     | 0.4862     | 0.5703     | ‚ùå No        | Baseline                    |
| 4    | #6   | Cost-Sensitive          | 0.8220     | **0.9183** | 0.2838     | 0.4336     | ‚ùå No        | **Extreme Recall** üéØ       |
| 5    | #3   | SMOTE                   | 0.8170     | 0.6144     | 0.5123     | 0.5587     | ‚ö†Ô∏è Yes       | -                           |
| 6    | #5   | SMOTETomek              | 0.8121     | 0.6046     | 0.5153     | 0.5564     | ‚ö†Ô∏è Yes       | -                           |
| 7    | #4   | ADASYN                  | 0.8106     | 0.6013     | 0.5041     | 0.5484     | ‚ö†Ô∏è Yes       | -                           |
| 8    | #1   | Baseline (OneHot)       | 0.7279     | 0.6144     | 0.3501     | 0.4460     | ‚ùå No        | -                           |

---

## ‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡πÅ‡∏ï‡πà‡∏•‡∏∞ Run

### [üìù Run #1 - Baseline (Class Weights Only)](runs/run_01_baseline.md)

**‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà:** 2025-12-07

**‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ:** Class Weights

**‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå:**

- XGBoost: Accuracy = 0.6887, Precision = 0.3501, Recall = 0.6144, F1 = 0.4460, ROC-AUC = 0.7279
- Logistic Regression ‡∏î‡∏µ‡∏Å‡∏ß‡πà‡∏≤ XGBoost (‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡πÉ‡∏ä‡πâ OneHot ‡∏ó‡∏±‡πâ‡∏á‡∏Ñ‡∏π‡πà)

**Key Insights:**

- Class weights ‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏û‡∏≠‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö imbalance ratio 4:1
- XGBoost ‡πÅ‡∏¢‡πà‡∏Å‡∏ß‡πà‡∏≤‡∏ó‡∏µ‡πà‡∏Ñ‡∏≤‡∏î ‚Üí ‡∏ï‡πâ‡∏≠‡∏á preprocessing ‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°

[‡∏≠‡πà‡∏≤‡∏ô‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏° ‚Üí](runs/run_01_baseline.md)

---

### [üìù Run #2 - Separate Preprocessing](runs/run_02_class_weights.md) ‚≠ê **BEST OVERALL**

**‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà:** 2025-12-12

**‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ:** Class Weights + Separate Preprocessing (OneHot for LR, Label Encoding for XGBoost)

**‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå (Threshold = 0.5):**

- XGBoost: Accuracy = **0.7880**, Precision = **0.4862**, Recall = **0.6895**, F1 = **0.5703**, ROC-AUC = **0.8379** ‚úÖ
- **‡πÄ‡∏Å‡∏¥‡∏ô‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢ ROC-AUC > 0.80 ‡πÅ‡∏•‡πâ‡∏ß!**

**üéØ Threshold Tuning Results (2026-01-16):**

‡∏õ‡∏£‡∏±‡∏ö threshold ‡∏à‡∏≤‡∏Å **0.5 ‚Üí 0.48** (‡∏õ‡∏£‡∏±‡∏ö‡πÅ‡∏Ñ‡πà‡∏ô‡∏¥‡∏î‡πÄ‡∏î‡∏µ‡∏¢‡∏ß!) ‡πÑ‡∏î‡πâ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏î‡∏µ‡∏Ç‡∏∂‡πâ‡∏ô:

- **Accuracy**: 0.786 (78.6%) ‚úÖ ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡∏∂‡πâ‡∏ô‡πÄ‡∏•‡πá‡∏Å‡∏ô‡πâ‡∏≠‡∏¢
- **Precision**: 0.4832 (48.32%) ‚úÖ ‡∏Ñ‡∏á‡∏ó‡∏µ‡πà
- **Recall**: **0.7059 (70.59%)** üéâ **‡πÄ‡∏Å‡∏¥‡∏ô‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢ 70% ‡πÅ‡∏•‡πâ‡∏ß!** (+1.64 pp)
- **F1**: 0.5737 (57.37%) ‚úÖ ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡∏∂‡πâ‡∏ô
- **ROC-AUC**: 0.8379 (83.79%) ‚úÖ ‡∏Ñ‡∏á‡∏ó‡∏µ‡πà

**üí° Key Insights:**

- **‡∏õ‡∏£‡∏±‡∏ö threshold ‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡πÄ‡∏•‡πá‡∏Å‡∏ô‡πâ‡∏≠‡∏¢ (0.5 ‚Üí 0.48) ‡∏ó‡∏≥‡πÉ‡∏´‡πâ Recall ‡πÄ‡∏Å‡∏¥‡∏ô‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢ 70% ‡πÅ‡∏•‡πâ‡∏ß!**
- ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á retrain model - ‡πÅ‡∏Ñ‡πà‡∏õ‡∏£‡∏±‡∏ö threshold ‡∏Å‡πá‡πÑ‡∏î‡πâ‡∏ú‡∏•‡∏î‡∏µ‡∏Ç‡∏∂‡πâ‡∏ô
- Precision ‡∏¢‡∏±‡∏á‡∏Ñ‡∏á‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏ó‡∏µ‡πà‡∏î‡∏µ (48.32%)
- F1 Score ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡∏∂‡πâ‡∏ô‡∏à‡∏≤‡∏Å 0.5703 ‚Üí 0.5737

**Key Insights:**

- Label Encoding ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏Å‡∏±‡∏ö XGBoost ‡∏°‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤ OneHot
- Features ‡∏•‡∏î‡∏•‡∏á 60% (‡∏à‡∏≤‡∏Å 25 ‚Üí 10) ‡πÅ‡∏ï‡πà performance ‡∏î‡∏µ‡∏Ç‡∏∂‡πâ‡∏ô
- SHAP plots ‡∏≠‡πà‡∏≤‡∏ô‡∏á‡πà‡∏≤‡∏¢‡∏Å‡∏ß‡πà‡∏≤‡∏°‡∏≤‡∏Å
- **Balance, NumOfProducts, IsActiveMember** ‡πÄ‡∏õ‡πá‡∏ô‡∏õ‡∏±‡∏à‡∏à‡∏±‡∏¢‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î

**Business Impact:**

- ‡∏õ‡∏£‡∏∞‡∏´‡∏¢‡∏±‡∏î‡πÑ‡∏î‡πâ: **12.5 ‡∏•‡πâ‡∏≤‡∏ô‡∏ö‡∏≤‡∏ó/‡∏õ‡∏µ** (‡∏à‡∏≤‡∏Å‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤ 2,000 ‡∏Ñ‡∏ô)
- ROI: **4,849%**

[‡∏≠‡πà‡∏≤‡∏ô‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏° ‚Üí](runs/run_02_class_weights.md)

---

### [üìù Run #3 - SMOTE Resampling](runs/run_03_smote.md)

**‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà:** 2025-12-14

**‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ:** SMOTE (Synthetic Minority Over-sampling)

**‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå:**

- XGBoost: Accuracy = 0.8020, Precision = 0.5123, Recall = 0.6144, F1 = 0.5587, ROC-AUC = 0.8170
- ‚ùå **Recall ‡∏•‡∏î‡∏•‡∏á 10.9%** ‡∏à‡∏≤‡∏Å Run #2

**Key Insights:**

- SMOTE ‡∏™‡∏£‡πâ‡∏≤‡∏á overfitting (CV = 0.91, Test = 0.82)
- Synthetic data ‡πÑ‡∏°‡πà‡∏ä‡πà‡∏ß‡∏¢‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á performance
- Class Weights ‡∏î‡∏µ‡∏Å‡∏ß‡πà‡∏≤ SMOTE ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö dataset ‡∏ô‡∏µ‡πâ

[‡∏≠‡πà‡∏≤‡∏ô‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏° ‚Üí](runs/run_03_smote.md)

---

### [üìù Run #4 - ADASYN Resampling](runs/run_04_adasyn.md)

**‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà:** 2025-12-15

**‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ:** ADASYN (Adaptive Synthetic Sampling)

**‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå:**

- XGBoost: Accuracy = 0.7980, Precision = 0.5041, Recall = 0.6013, F1 = 0.5484, ROC-AUC = 0.8106
- ‚ùå **‡πÅ‡∏¢‡πà‡∏Å‡∏ß‡πà‡∏≤ SMOTE ‡πÉ‡∏ô‡∏ó‡∏∏‡∏Å metrics**

**Key Insights:**

- ADASYN ‡∏™‡∏£‡πâ‡∏≤‡∏á overfitting ‡∏£‡∏∏‡∏ô‡πÅ‡∏£‡∏á‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î (Recall variance = ¬±0.1363)
- Focus ‡∏ó‡∏µ‡πà hard samples ‡∏™‡∏£‡πâ‡∏≤‡∏á noise ‡∏°‡∏≤‡∏Å‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ
- ‡πÑ‡∏°‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏Å‡∏±‡∏ö dataset ‡∏ô‡∏µ‡πâ

[‡∏≠‡πà‡∏≤‡∏ô‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏° ‚Üí](runs/run_04_adasyn.md)

---

### [üìù Run #5 - SMOTETomek Resampling](runs/run_05_smotetomek.md)

**‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà:** 2025-12-15

**‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ:** SMOTETomek (Hybrid: SMOTE + Tomek Links)

**‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå:**

- XGBoost: Accuracy = 0.8033, Precision = **0.5153** (‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î!), Recall = 0.6046, F1 = 0.5564, ROC-AUC = 0.8121
- ‚úÖ **Precision ‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î‡πÉ‡∏ô‡∏ó‡∏∏‡∏Å Runs**
- ‚ùå **Recall ‡∏¢‡∏±‡∏á‡∏ï‡πà‡∏≥** (‡∏•‡∏î‡∏•‡∏á 12.3% ‡∏à‡∏≤‡∏Å Run #2)

**Key Insights:**

- Hybrid approach ‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡πÅ‡∏Å‡πâ‡∏õ‡∏±‡∏ç‡∏´‡∏≤ overfitting
- Tomek Links ‡∏≠‡∏≤‡∏à‡∏•‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏ä‡∏ô‡πå (24% ‡∏Ç‡∏≠‡∏á majority class)
- Trade-off: Precision ‡∏™‡∏π‡∏á‡∏Ç‡∏∂‡πâ‡∏ô ‡πÅ‡∏ï‡πà Recall ‡∏•‡∏î‡∏•‡∏á (‡πÑ‡∏°‡πà‡∏Ñ‡∏∏‡πâ‡∏°‡∏Ñ‡πà‡∏≤)

[‡∏≠‡πà‡∏≤‡∏ô‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏° ‚Üí](runs/run_05_smotetomek.md)

---

### [üìù Run #6 - Cost-Sensitive Learning](runs/run_06_cost_sensitive.md) üéØ **HIGHEST RECALL**

**‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà:** 2026-01-11

**‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ:** Cost-Sensitive Learning (cost_ratio = 10.0)

**‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå:**

- XGBoost: Accuracy = 0.5107, Precision = 0.2838, Recall = **0.9183** üöÄ, F1 = 0.4336, ROC-AUC = 0.8220
- **Recall ‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î: 91.83%** (‡πÄ‡∏Å‡∏¥‡∏ô‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢ 70% ‡πÑ‡∏õ‡∏ñ‡∏∂‡∏á 21.83%!)
- ‡∏à‡∏±‡∏ö‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤ Churn ‡πÑ‡∏î‡πâ **281/306 ‡∏Ñ‡∏ô** (‡∏û‡∏•‡∏≤‡∏î‡πÅ‡∏Ñ‡πà 25 ‡∏Ñ‡∏ô!)

**Key Insights:**

- Cost Ratio 20.0 ‡πÉ‡∏´‡πâ Recall ‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î (95.10%)
- Trade-off: Recall ‡∏™‡∏π‡∏á‡∏°‡∏≤‡∏Å ‡πÅ‡∏ï‡πà Precision ‡∏ï‡πà‡∏≥ (28.38%)
- ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏Å‡∏±‡∏ö‡∏ò‡∏ô‡∏≤‡∏Ñ‡∏≤‡∏£‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏ó‡∏µ‡∏° Retention ‡∏Ç‡∏ô‡∏≤‡∏î‡πÉ‡∏´‡∏ç‡πà

**Business Impact:**

- ‡∏õ‡∏£‡∏∞‡∏´‡∏¢‡∏±‡∏î‡πÑ‡∏î‡πâ: **16.3 ‡∏•‡πâ‡∏≤‡∏ô‡∏ö‡∏≤‡∏ó** (‡∏°‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤ Run #2 ‡∏ñ‡∏∂‡∏á 3.76M ‡∏ö‡∏≤‡∏ó!)
- ROI: **3,192%**
- ‡∏ï‡πâ‡∏≠‡∏á‡∏ï‡∏¥‡∏î‡∏ï‡πà‡∏≠‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤ 991 ‡∏Ñ‡∏ô (‡∏°‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤ Run #2)

[‡∏≠‡πà‡∏≤‡∏ô‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏° ‚Üí](runs/run_06_cost_sensitive.md)

---

## ‡πÅ‡∏ô‡∏ß‡∏ó‡∏≤‡∏á‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á

**‚úÖ Completed:**

- [x] **Separate Preprocessing for LR vs XGBoost** - ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à! XGBoost ‡∏î‡∏µ‡∏Ç‡∏∂‡πâ‡∏ô 15% ‡πÉ‡∏ô ROC-AUC
- [x] **Achieve ROC-AUC > 0.80** - ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à! ‡πÑ‡∏î‡πâ 0.8379
- [x] **Test SMOTE Resampling** - ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡πÅ‡∏•‡πâ‡∏ß! ‡πÅ‡∏ï‡πà‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏ä‡πà‡∏ß‡∏¢‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á performance (Recall ‡∏•‡∏î‡∏•‡∏á 7.5 pp.)
- [x] **Test ADASYN Resampling** - ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡πÅ‡∏•‡πâ‡∏ß! ‡πÅ‡∏¢‡πà‡∏Å‡∏ß‡πà‡∏≤ SMOTE (Recall ‡∏•‡∏î‡∏•‡∏á 8.8 pp.)
- [x] **Test SMOTETomek (Hybrid)** - ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡πÅ‡∏•‡πâ‡∏ß! Precision ‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î ‡πÅ‡∏ï‡πà Recall ‡∏¢‡∏±‡∏á‡∏ï‡πà‡∏≥ (‡∏•‡∏î‡∏•‡∏á 8.5 pp.)
- [x] **Test Cost-Sensitive Learning** - ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à! Recall ‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î (91.83%) ‡πÅ‡∏ï‡πà Precision ‡∏ï‡πà‡∏≥ (28.38%)

**üìä ‡∏™‡∏£‡∏∏‡∏õ‡∏à‡∏≤‡∏Å‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î:**

| Method                | ROC-AUC    | Recall     | Precision  | F1         | Ranking     |
| --------------------- | ---------- | ---------- | ---------- | ---------- | ----------- |
| **Class Weights**     | **0.8379** | 0.6895     | **0.4862** | **0.5703** | ü•á **Best** |
| Cost-Sensitive (10.0) | 0.8220     | **0.9183** | 0.2838     | 0.4336     | ü•à 2nd      |
| SMOTE                 | 0.8170     | 0.6144     | 0.5123     | 0.5587     | ü•â 3rd      |
| SMOTETomek            | 0.8121     | 0.6046     | 0.5153     | 0.5564     | 4th         |
| ADASYN                | 0.8106     | 0.6013     | 0.5041     | 0.5484     | 5th         |

**üí° ‡∏Ç‡πâ‡∏≠‡∏™‡∏£‡∏∏‡∏õ:**

- ‚úÖ **Class Weights (Run #2) ‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏†‡∏≤‡∏û‡∏£‡∏ß‡∏°** - Balance, ROI ‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î
- ‚úÖ **Cost-Sensitive (Run #6) ‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Recall** - ‡∏à‡∏±‡∏ö Churn ‡πÑ‡∏î‡πâ‡∏°‡∏≤‡∏Å‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î
- ‚ùå **Synthetic Sampling ‡∏ó‡∏∏‡∏Å‡∏ß‡∏¥‡∏ò‡∏µ‡∏™‡∏£‡πâ‡∏≤‡∏á overfitting ‡πÅ‡∏•‡∏∞‡∏•‡∏î Recall**
- ‚ùå **Hybrid approach (SMOTETomek) ‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡πÅ‡∏Å‡πâ‡∏õ‡∏±‡∏ç‡∏´‡∏≤**
- ‚úÖ **‡∏Ñ‡∏ß‡∏£‡πÉ‡∏ä‡πâ Run #2 ‡πÄ‡∏õ‡πá‡∏ô default model, Run #6 ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö campaign ‡∏û‡∏¥‡πÄ‡∏®‡∏©**

---

## Next Immediate Steps

**‚úÖ All Major Experiments - COMPLETED:**

- [x] **Run #2: Class Weights** - ‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏†‡∏≤‡∏û‡∏£‡∏ß‡∏°
- [x] **Run #3: SMOTE** - ‡πÑ‡∏°‡πà‡∏î‡∏µ‡πÄ‡∏ó‡πà‡∏≤ Class Weights
- [x] **Run #4: ADASYN** - ‡πÅ‡∏¢‡πà‡∏Å‡∏ß‡πà‡∏≤ SMOTE
- [x] **Run #5: SMOTETomek** - Precision ‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î ‡πÅ‡∏ï‡πà Recall ‡∏ï‡πà‡∏≥
- [x] **Run #6: Cost-Sensitive Learning** - Recall ‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î (91.83%)!
- [x] **Threshold Tuning (Run #2)** - ‚úÖ **‡πÄ‡∏Å‡∏¥‡∏ô‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢ Recall 70% ‡πÅ‡∏•‡πâ‡∏ß! (70.59%)**

**üìä ‡∏™‡∏£‡∏∏‡∏õ:**

- **Run #2 (Class Weights)** = Best Overall (F1, ROC-AUC, ROI)
- **Run #2 + Threshold 0.48** = **‡πÄ‡∏Å‡∏¥‡∏ô‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢ Recall 70% ‡πÅ‡∏•‡πâ‡∏ß!** ‚≠ê
- **Run #6 (Cost-Sensitive)** = Best Recall (91.83%)

---

**‚ùå ‡πÑ‡∏°‡πà‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥ (‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡πÅ‡∏•‡πâ‡∏ß‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏ú‡∏•):**

- ‚ùå **SMOTEENN** - ‡∏Ñ‡∏≤‡∏î‡∏ß‡πà‡∏≤‡∏à‡∏∞‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢ SMOTETomek
- ‚ùå **Focal Loss** - ‡∏ã‡∏±‡∏ö‡∏ã‡πâ‡∏≠‡∏ô‡πÅ‡∏•‡∏∞‡πÑ‡∏°‡πà‡∏Ñ‡∏∏‡πâ‡∏°‡∏Ñ‡πà‡∏≤
- ‚ùå **Synthetic Sampling ‡∏≠‡∏∑‡πà‡∏ô‡πÜ** - ‡πÑ‡∏°‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏Å‡∏±‡∏ö dataset ‡∏ô‡∏µ‡πâ (imbalance ratio 4:1)

---

## üìå Final Recommendations

**‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Production:**

1. **Most Balanced: Run #2.2 (Hyperparameter Tuned + Threshold 0.54)** ‚≠ê **RECOMMENDED**

   - ‡πÉ‡∏ä‡πâ‡πÄ‡∏õ‡πá‡∏ô default model ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ
   - **Recall = 70.26%** ‚úÖ ‡πÄ‡∏Å‡∏¥‡∏ô‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢ 70% ‡∏û‡∏≠‡∏î‡∏µ!
   - **Precision = 49.54%** ‚úÖ ‡∏™‡∏π‡∏á‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡πÉ‡∏ô‡∏Å‡∏•‡∏∏‡πà‡∏° Recall >= 70%!
   - **F1 = 58.11%** üèÜ **‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î!**
   - ROC-AUC = 84.61% ‚úÖ
   - Accuracy = 79.33% ‚úÖ
   - **Balance ‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á Precision & Recall ‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î!**

2. **Highest Recall: Run #2.1 (Hyperparameter Tuned)** üöÄ

   - ‡πÉ‡∏ä‡πâ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£ Recall ‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î
   - **Recall = 74.51%** ‚úÖ ‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î!
   - **ROC-AUC = 84.61%** ‚úÖ
   - F1 = 0.5794
   - Precision = 0.4740
   - **Best Parameters:** n_estimators=50, max_depth=3, learning_rate=0.1, subsample=0.6

3. **Simplicity: Run #2 (Baseline)**

   - ‡πÉ‡∏ä‡πâ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£ model ‡∏ó‡∏µ‡πà simple
   - Recall = 68.95%, Precision = 48.62%
   - F1 = 0.5703, ROC-AUC = 0.8379
   - ‡πÉ‡∏ä‡πâ default hyperparameters

4. **Special Campaign: Run #6 (Cost-Sensitive, Ratio 20.0)**
   - ‡πÉ‡∏ä‡πâ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö campaign ‡∏û‡∏¥‡πÄ‡∏®‡∏©‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏ö Churn ‡πÉ‡∏´‡πâ‡πÑ‡∏î‡πâ‡∏°‡∏≤‡∏Å‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î
   - Recall = 95.10% (‡∏û‡∏•‡∏≤‡∏î‡πÅ‡∏Ñ‡πà 15 ‡∏Ñ‡∏ô!)
   - ‡∏¢‡∏≠‡∏°‡∏£‡∏±‡∏ö False Positive ‡∏™‡∏π‡∏á

**‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ò‡∏ô‡∏≤‡∏Ñ‡∏≤‡∏£:**

- **‡∏ò‡∏ô‡∏≤‡∏Ñ‡∏≤‡∏£‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ (‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£ Balance)** ‚Üí ‡πÉ‡∏ä‡πâ Run #2.2 (Threshold 0.54) ‚≠ê **‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥!**
- **‡∏ò‡∏ô‡∏≤‡∏Ñ‡∏≤‡∏£‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£ Recall ‡∏™‡∏π‡∏á** ‚Üí ‡πÉ‡∏ä‡πâ Run #2.1 (Hyperparameter Tuned) üöÄ
- **‡∏ò‡∏ô‡∏≤‡∏Ñ‡∏≤‡∏£‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£ Simplicity** ‚Üí ‡πÉ‡∏ä‡πâ Run #2 (Baseline)
- **‡∏ò‡∏ô‡∏≤‡∏Ñ‡∏≤‡∏£‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏ó‡∏µ‡∏° Retention ‡∏Ç‡∏ô‡∏≤‡∏î‡πÉ‡∏´‡∏ç‡πà** ‚Üí ‡πÉ‡∏ä‡πâ Run #6 (Cost-Sensitive)

---

**Last Updated:** 2026-01-16

**Total Experiments:** 6 Runs + Hyperparameter Tuning + Threshold Tuning

**Best Model (Balanced):** Run #2.2 - Recall = **70.26%** ‚úÖ, Precision = **49.54%** ‚úÖ, F1 = **58.11%** üèÜ, ROC-AUC = **84.61%** ‚úÖ

**Best Model (Highest Recall):** Run #2.1 - Recall = **74.51%** ‚úÖ, ROC-AUC = **84.61%** ‚úÖ

**Highest Recall Overall:** Run #6 (Cost-Sensitive) - Recall = 0.9183
