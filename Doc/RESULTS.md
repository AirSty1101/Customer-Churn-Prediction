# Experiment Results - Customer Churn Prediction

‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏•‡∏≠‡∏á‡πÅ‡∏•‡∏∞ metrics ‡∏Ç‡∏≠‡∏á‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏£‡∏≠‡∏ö‡∏Å‡∏≤‡∏£ train model

---

## üìë Table of Contents

**Quick Links:**

- [üéØ ‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢ Metrics](#‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢-metrics)
- [üìä ‡∏™‡∏£‡∏∏‡∏õ‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö](#‡∏™‡∏£‡∏∏‡∏õ‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö)
- [üìù ‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡πÅ‡∏ï‡πà‡∏•‡∏∞ Run](#‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡πÅ‡∏ï‡πà‡∏•‡∏∞-run)
- [üí° ‡πÅ‡∏ô‡∏ß‡∏ó‡∏≤‡∏á‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á](#‡πÅ‡∏ô‡∏ß‡∏ó‡∏≤‡∏á‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á)
- [üéØ Next Steps](#next-immediate-steps)

---

## ‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢ Metrics

| Metric        | ‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢ | ‡πÄ‡∏´‡∏ï‡∏∏‡∏ú‡∏•                                   | ‡∏ú‡∏•‡∏Å‡∏£‡∏∞‡∏ó‡∏ö‡∏ó‡∏≤‡∏á‡∏ò‡∏∏‡∏£‡∏Å‡∏¥‡∏à                                                 |
| ------------- | -------- | ---------------------------------------- | ---------------------------------------------------------------- |
| **Recall**    | > 0.70   | ‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î - ‡∏ï‡πâ‡∏≠‡∏á‡∏à‡∏±‡∏ö Churn ‡πÑ‡∏î‡πâ‡∏°‡∏≤‡∏Å‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î | ‡∏à‡∏±‡∏ö‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤‡∏ó‡∏µ‡πà‡∏à‡∏∞ Churn ‡πÑ‡∏î‡πâ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ô‡πâ‡∏≠‡∏¢ 70% ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏°‡∏µ‡πÇ‡∏≠‡∏Å‡∏≤‡∏™‡∏£‡∏±‡∏Å‡∏©‡∏≤‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤‡πÑ‡∏ß‡πâ |
| **Precision** | > 0.60   | ‡∏•‡∏î False Positive                        | ‡∏•‡∏î‡∏ï‡πâ‡∏ô‡∏ó‡∏∏‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏¥‡∏î‡∏ï‡πà‡∏≠‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤‡∏ú‡∏¥‡∏î‡∏Ñ‡∏ô (‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ Churn ‡∏à‡∏£‡∏¥‡∏á)              |
| **F1 Score**  | > 0.65   | ‡∏™‡∏°‡∏î‡∏∏‡∏•‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á Precision & Recall          | ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏°‡∏î‡∏∏‡∏•‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏ö Churn ‡πÑ‡∏î‡πâ ‡πÅ‡∏•‡∏∞‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥                   |
| **ROC-AUC**   | > 0.80   | ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÅ‡∏¢‡∏Å class ‡πÇ‡∏î‡∏¢‡∏£‡∏ß‡∏°               | Model ‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÅ‡∏¢‡∏Å‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤ Churn/Not Churn ‡πÑ‡∏î‡πâ‡∏î‡∏µ                |

**‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏:** ‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏•‡πà‡∏≤‡∏ô‡∏µ‡πâ‡∏ï‡∏±‡πâ‡∏á‡∏Ç‡∏∂‡πâ‡∏ô‡∏à‡∏≤‡∏Å‡∏Å‡∏≤‡∏£‡∏û‡∏¥‡∏à‡∏≤‡∏£‡∏ì‡∏≤‡∏ß‡πà‡∏≤:

- **Recall ‡∏™‡∏π‡∏á** = ‡∏à‡∏±‡∏ö‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤‡∏ó‡∏µ‡πà‡∏à‡∏∞ Churn ‡πÑ‡∏î‡πâ‡∏°‡∏≤‡∏Å ‚Üí ‡∏•‡∏î‡∏Å‡∏≤‡∏£‡∏™‡∏π‡∏ç‡πÄ‡∏™‡∏µ‡∏¢‡∏£‡∏≤‡∏¢‡πÑ‡∏î‡πâ
- **Precision ‡∏û‡∏≠‡πÉ‡∏ä‡πâ** = ‡∏¢‡∏≠‡∏°‡∏£‡∏±‡∏ö False Positive ‡∏ö‡πâ‡∏≤‡∏á ‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡∏ï‡πâ‡∏ô‡∏ó‡∏∏‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏¥‡∏î‡∏ï‡πà‡∏≠‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤‡∏ï‡πà‡∏≥‡∏Å‡∏ß‡πà‡∏≤‡∏Å‡∏≤‡∏£‡∏™‡∏π‡∏ç‡πÄ‡∏™‡∏µ‡∏¢‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤
- **ROC-AUC > 0.80** = ‡πÄ‡∏õ‡πá‡∏ô‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô‡∏™‡∏≤‡∏Å‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö model ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÑ‡∏î‡πâ‡∏à‡∏£‡∏¥‡∏á

---

## ‡∏™‡∏£‡∏∏‡∏õ‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö

### Test Set Performance

| Run | Model                                                       | XGB<br>Accuracy | XGB<br>Precision | XGB<br>Recall | XGB<br>F1  | XGB<br>ROC-AUC |
| --- | ----------------------------------------------------------- | --------------- | ---------------- | ------------- | ---------- | -------------- |
| #1  | Baseline<br>(OneHot for both)                               | 0.6887          | 0.3501           | 0.6144        | 0.4460     | 0.7279         |
| #2  | Separate Preprocessing<br>(OneHot for LR, Label for XGB) ‚≠ê | **0.7880**      | **0.4862**       | 0.6895        | **0.5703** | **0.8379**     |
| #3  | SMOTE Resampling<br>(OneHot for LR, Label for XGB)          | 0.8020          | 0.5123           | 0.6144        | 0.5587     | 0.8170         |
| #4  | ADASYN Resampling<br>(OneHot for LR, Label for XGB)         | 0.7980          | 0.5041           | 0.6013        | 0.5484     | 0.8106         |
| #5  | SMOTETomek Resampling<br>(OneHot for LR, Label for XGB)     | 0.8033          | 0.5153           | 0.6046        | 0.5564     | 0.8121         |
| #6  | Cost-Sensitive Learning<br>(cost_ratio=10.0) üéØ             | 0.5107          | 0.2838           | **0.9183**    | 0.4336     | 0.8220         |

### Key Takeaways

1. **Run #2 (Class Weights) ‡∏¢‡∏±‡∏á‡∏Ñ‡∏á‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏†‡∏≤‡∏û‡∏£‡∏ß‡∏°!** ü•á

   - XGBoost: ROC-AUC = 0.8379, F1 = 0.5703, Recall = 0.6895
   - Balance ‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á Precision & Recall ‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î
   - ROI ‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î (5,668%)
   - ‚úÖ **‡πÄ‡∏Å‡∏¥‡∏ô‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢ ROC-AUC > 0.80 ‡πÅ‡∏•‡πâ‡∏ß!**

2. **Run #6 (Cost-Sensitive) ‡πÉ‡∏´‡πâ Recall ‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î!** üöÄ

   - XGBoost: Recall = **0.9183** (+22.88 pp ‡∏à‡∏≤‡∏Å Run #2)
   - ‡∏à‡∏±‡∏ö‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤ Churn ‡πÑ‡∏î‡πâ 281/306 ‡∏Ñ‡∏ô (‡∏û‡∏•‡∏≤‡∏î‡πÅ‡∏Ñ‡πà 25 ‡∏Ñ‡∏ô!)
   - ‡πÅ‡∏ï‡πà Precision ‡∏ï‡πà‡∏≥ (0.2838) - ‡∏ï‡∏¥‡∏î‡∏ï‡πà‡∏≠‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤‡∏ú‡∏¥‡∏î‡∏Ñ‡∏ô‡∏°‡∏≤‡∏Å
   - ‡∏õ‡∏£‡∏∞‡∏´‡∏¢‡∏±‡∏î‡πÑ‡∏î‡πâ 16.3M ‡∏ö‡∏≤‡∏ó (‡∏°‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤ Run #2 ‡∏ñ‡∏∂‡∏á 3.76M ‡∏ö‡∏≤‡∏ó!)

3. **‡∏ó‡∏î‡∏™‡∏≠‡∏ö Synthetic Sampling ‡∏Ñ‡∏£‡∏ö‡∏ó‡∏±‡πâ‡∏á 3 ‡∏ß‡∏¥‡∏ò‡∏µ‡πÅ‡∏•‡πâ‡∏ß:**

   - SMOTE (Run #3): ROC-AUC = 0.8170, Recall = 0.6144
   - SMOTETomek (Run #5): ROC-AUC = 0.8121, Recall = 0.6046, **Precision ‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î (0.5153)**
   - ADASYN (Run #4): ROC-AUC = 0.8106, Recall = 0.6013

4. **Synthetic Sampling ‡∏ó‡∏∏‡∏Å‡∏ß‡∏¥‡∏ò‡∏µ‡∏™‡∏£‡πâ‡∏≤‡∏á overfitting:**

   - Run #3: CV ROC-AUC = 0.91, Test = 0.82 (‡∏ï‡πà‡∏≤‡∏á‡∏Å‡∏±‡∏ô 9%)
   - Run #4: CV ROC-AUC = 0.91, Test = 0.81 (‡∏ï‡πà‡∏≤‡∏á‡∏Å‡∏±‡∏ô 10%)
   - Run #5: CV ROC-AUC = 0.91, Test = 0.81 (‡∏ï‡πà‡∏≤‡∏á‡∏Å‡∏±‡∏ô 10%)

5. **Recall Comparison:**

   - Run #6 (Cost-Sensitive): Recall = **91.83%** ü•á (‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î!)
   - Run #2 (Class Weights): Recall = **68.95%** ü•à
   - Run #4 (ADASYN): Recall = 71.90%
   - Run #3 (SMOTE): Recall = 61.44%
   - Run #5 (SMOTETomek): Recall = 60.46%

6. **Cost-Sensitive Learning Findings:**

   - Cost Ratio 20.0 ‡πÉ‡∏´‡πâ Recall ‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î (95.10%)
   - ‡∏¢‡∏¥‡πà‡∏á Cost Ratio ‡∏™‡∏π‡∏á ‚Üí Recall ‡πÄ‡∏û‡∏¥‡πà‡∏°, Precision ‡∏•‡∏î
   - ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏Å‡∏±‡∏ö‡∏ò‡∏ô‡∏≤‡∏Ñ‡∏≤‡∏£‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏ó‡∏µ‡∏° Retention ‡∏Ç‡∏ô‡∏≤‡∏î‡πÉ‡∏´‡∏ç‡πà

7. **‡πÅ‡∏¢‡∏Å preprocessing ‡∏ï‡∏≤‡∏° model** ‡∏ó‡∏≥‡πÉ‡∏´‡πâ XGBoost ‡∏î‡∏µ‡∏Ç‡∏∂‡πâ‡∏ô 15% ‡πÉ‡∏ô ROC-AUC (Run #1 ‚Üí Run #2)

8. **Recall ‡πÄ‡∏õ‡πá‡∏ô metric ‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î** - ‡πÅ‡∏•‡∏∞ Run #6 ‡πÉ‡∏´‡πâ Recall ‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î (91.83%)

### Ranking Summary

| Rank | Run | Method            | ROC-AUC    | Recall     | Precision  | F1         | Overfitting? | Best For           |
| ---- | --- | ----------------- | ---------- | ---------- | ---------- | ---------- | ------------ | ------------------ |
| ü•á 1 | #2  | Class Weights     | **0.8379** | 0.6895     | **0.4862** | **0.5703** | ‚ùå No        | **Overall Best**   |
| ü•à 2 | #6  | Cost-Sensitive    | 0.8220     | **0.9183** | 0.2838     | 0.4336     | ‚ùå No        | **Highest Recall** |
| ü•â 3 | #3  | SMOTE             | 0.8170     | 0.6144     | 0.5123     | 0.5587     | ‚ö†Ô∏è Yes       | -                  |
| 4    | #5  | SMOTETomek        | 0.8121     | 0.6046     | 0.5153     | 0.5564     | ‚ö†Ô∏è Yes       | Highest Precision  |
| 5    | #4  | ADASYN            | 0.8106     | 0.6013     | 0.5041     | 0.5484     | ‚ö†Ô∏è Yes       | -                  |
| 6    | #1  | Baseline (OneHot) | 0.7279     | 0.6144     | 0.3501     | 0.4460     | ‚ùå No        | -                  |

---

## ‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡πÅ‡∏ï‡πà‡∏•‡∏∞ Run

### [üìù Run #1 - Baseline (Class Weights Only)](runs/run_01_baseline.md)

**‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà:** 2025-12-07

**‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ:** Class Weights

**‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå:**

- XGBoost: Accuracy = 0.6887, Precision = 0.3501, Recall = 0.6144, F1 = 0.4460, ROC-AUC = 0.7279
- Logistic Regression ‡∏î‡∏µ‡∏Å‡∏ß‡πà‡∏≤ XGBoost (‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡πÉ‡∏ä‡πâ OneHot ‡∏ó‡∏±‡πâ‡∏á‡∏Ñ‡∏π‡πà)

**Key Insights:**

- Class weights ‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏û‡∏≠‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö imbalance ratio 4:1
- XGBoost ‡πÅ‡∏¢‡πà‡∏Å‡∏ß‡πà‡∏≤‡∏ó‡∏µ‡πà‡∏Ñ‡∏≤‡∏î ‚Üí ‡∏ï‡πâ‡∏≠‡∏á preprocessing ‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°

[‡∏≠‡πà‡∏≤‡∏ô‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏° ‚Üí](runs/run_01_baseline.md)

---

### [üìù Run #2 - Separate Preprocessing](runs/run_02_class_weights.md) ‚≠ê **BEST OVERALL**

**‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà:** 2025-12-12

**‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ:** Class Weights + Separate Preprocessing (OneHot for LR, Label Encoding for XGBoost)

**‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå:**

- XGBoost: Accuracy = **0.7880**, Precision = **0.4862**, Recall = **0.6895**, F1 = **0.5703**, ROC-AUC = **0.8379** ‚úÖ
- **‡πÄ‡∏Å‡∏¥‡∏ô‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢ ROC-AUC > 0.80 ‡πÅ‡∏•‡πâ‡∏ß!**

**Key Insights:**

- Label Encoding ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏Å‡∏±‡∏ö XGBoost ‡∏°‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤ OneHot
- Features ‡∏•‡∏î‡∏•‡∏á 60% (‡∏à‡∏≤‡∏Å 25 ‚Üí 10) ‡πÅ‡∏ï‡πà performance ‡∏î‡∏µ‡∏Ç‡∏∂‡πâ‡∏ô
- SHAP plots ‡∏≠‡πà‡∏≤‡∏ô‡∏á‡πà‡∏≤‡∏¢‡∏Å‡∏ß‡πà‡∏≤‡∏°‡∏≤‡∏Å
- **Balance, NumOfProducts, IsActiveMember** ‡πÄ‡∏õ‡πá‡∏ô‡∏õ‡∏±‡∏à‡∏à‡∏±‡∏¢‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î

**Business Impact:**

- ‡∏õ‡∏£‡∏∞‡∏´‡∏¢‡∏±‡∏î‡πÑ‡∏î‡πâ: **12.5 ‡∏•‡πâ‡∏≤‡∏ô‡∏ö‡∏≤‡∏ó/‡∏õ‡∏µ** (‡∏à‡∏≤‡∏Å‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤ 2,000 ‡∏Ñ‡∏ô)
- ROI: **4,849%**

[‡∏≠‡πà‡∏≤‡∏ô‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏° ‚Üí](runs/run_02_class_weights.md)

---

### [üìù Run #3 - SMOTE Resampling](runs/run_03_smote.md)

**‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà:** 2025-12-14

**‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ:** SMOTE (Synthetic Minority Over-sampling)

**‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå:**

- XGBoost: Accuracy = 0.8020, Precision = 0.5123, Recall = 0.6144, F1 = 0.5587, ROC-AUC = 0.8170
- ‚ùå **Recall ‡∏•‡∏î‡∏•‡∏á 10.9%** ‡∏à‡∏≤‡∏Å Run #2

**Key Insights:**

- SMOTE ‡∏™‡∏£‡πâ‡∏≤‡∏á overfitting (CV = 0.91, Test = 0.82)
- Synthetic data ‡πÑ‡∏°‡πà‡∏ä‡πà‡∏ß‡∏¢‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á performance
- Class Weights ‡∏î‡∏µ‡∏Å‡∏ß‡πà‡∏≤ SMOTE ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö dataset ‡∏ô‡∏µ‡πâ

[‡∏≠‡πà‡∏≤‡∏ô‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏° ‚Üí](runs/run_03_smote.md)

---

### [üìù Run #4 - ADASYN Resampling](runs/run_04_adasyn.md)

**‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà:** 2025-12-15

**‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ:** ADASYN (Adaptive Synthetic Sampling)

**‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå:**

- XGBoost: Accuracy = 0.7980, Precision = 0.5041, Recall = 0.6013, F1 = 0.5484, ROC-AUC = 0.8106
- ‚ùå **‡πÅ‡∏¢‡πà‡∏Å‡∏ß‡πà‡∏≤ SMOTE ‡πÉ‡∏ô‡∏ó‡∏∏‡∏Å metrics**

**Key Insights:**

- ADASYN ‡∏™‡∏£‡πâ‡∏≤‡∏á overfitting ‡∏£‡∏∏‡∏ô‡πÅ‡∏£‡∏á‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î (Recall variance = ¬±0.1363)
- Focus ‡∏ó‡∏µ‡πà hard samples ‡∏™‡∏£‡πâ‡∏≤‡∏á noise ‡∏°‡∏≤‡∏Å‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ
- ‡πÑ‡∏°‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏Å‡∏±‡∏ö dataset ‡∏ô‡∏µ‡πâ

[‡∏≠‡πà‡∏≤‡∏ô‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏° ‚Üí](runs/run_04_adasyn.md)

---

### [üìù Run #5 - SMOTETomek Resampling](runs/run_05_smotetomek.md)

**‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà:** 2025-12-15

**‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ:** SMOTETomek (Hybrid: SMOTE + Tomek Links)

**‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå:**

- XGBoost: Accuracy = 0.8033, Precision = **0.5153** (‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î!), Recall = 0.6046, F1 = 0.5564, ROC-AUC = 0.8121
- ‚úÖ **Precision ‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î‡πÉ‡∏ô‡∏ó‡∏∏‡∏Å Runs**
- ‚ùå **Recall ‡∏¢‡∏±‡∏á‡∏ï‡πà‡∏≥** (‡∏•‡∏î‡∏•‡∏á 12.3% ‡∏à‡∏≤‡∏Å Run #2)

**Key Insights:**

- Hybrid approach ‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡πÅ‡∏Å‡πâ‡∏õ‡∏±‡∏ç‡∏´‡∏≤ overfitting
- Tomek Links ‡∏≠‡∏≤‡∏à‡∏•‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏ä‡∏ô‡πå (24% ‡∏Ç‡∏≠‡∏á majority class)
- Trade-off: Precision ‡∏™‡∏π‡∏á‡∏Ç‡∏∂‡πâ‡∏ô ‡πÅ‡∏ï‡πà Recall ‡∏•‡∏î‡∏•‡∏á (‡πÑ‡∏°‡πà‡∏Ñ‡∏∏‡πâ‡∏°‡∏Ñ‡πà‡∏≤)

[‡∏≠‡πà‡∏≤‡∏ô‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏° ‚Üí](runs/run_05_smotetomek.md)

---

### [üìù Run #6 - Cost-Sensitive Learning](runs/run_06_cost_sensitive.md) üéØ **HIGHEST RECALL**

**‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà:** 2026-01-11

**‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ:** Cost-Sensitive Learning (cost_ratio = 10.0)

**‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå:**

- XGBoost: Accuracy = 0.5107, Precision = 0.2838, Recall = **0.9183** üöÄ, F1 = 0.4336, ROC-AUC = 0.8220
- **Recall ‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î: 91.83%** (‡πÄ‡∏Å‡∏¥‡∏ô‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢ 70% ‡πÑ‡∏õ‡∏ñ‡∏∂‡∏á 21.83%!)
- ‡∏à‡∏±‡∏ö‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤ Churn ‡πÑ‡∏î‡πâ **281/306 ‡∏Ñ‡∏ô** (‡∏û‡∏•‡∏≤‡∏î‡πÅ‡∏Ñ‡πà 25 ‡∏Ñ‡∏ô!)

**Key Insights:**

- Cost Ratio 20.0 ‡πÉ‡∏´‡πâ Recall ‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î (95.10%)
- Trade-off: Recall ‡∏™‡∏π‡∏á‡∏°‡∏≤‡∏Å ‡πÅ‡∏ï‡πà Precision ‡∏ï‡πà‡∏≥ (28.38%)
- ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏Å‡∏±‡∏ö‡∏ò‡∏ô‡∏≤‡∏Ñ‡∏≤‡∏£‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏ó‡∏µ‡∏° Retention ‡∏Ç‡∏ô‡∏≤‡∏î‡πÉ‡∏´‡∏ç‡πà

**Business Impact:**

- ‡∏õ‡∏£‡∏∞‡∏´‡∏¢‡∏±‡∏î‡πÑ‡∏î‡πâ: **16.3 ‡∏•‡πâ‡∏≤‡∏ô‡∏ö‡∏≤‡∏ó** (‡∏°‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤ Run #2 ‡∏ñ‡∏∂‡∏á 3.76M ‡∏ö‡∏≤‡∏ó!)
- ROI: **3,192%**
- ‡∏ï‡πâ‡∏≠‡∏á‡∏ï‡∏¥‡∏î‡∏ï‡πà‡∏≠‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤ 991 ‡∏Ñ‡∏ô (‡∏°‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤ Run #2)

[‡∏≠‡πà‡∏≤‡∏ô‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏° ‚Üí](runs/run_06_cost_sensitive.md)

---

## ‡πÅ‡∏ô‡∏ß‡∏ó‡∏≤‡∏á‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á

**‚úÖ Completed:**

- [x] **Separate Preprocessing for LR vs XGBoost** - ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à! XGBoost ‡∏î‡∏µ‡∏Ç‡∏∂‡πâ‡∏ô 15% ‡πÉ‡∏ô ROC-AUC
- [x] **Achieve ROC-AUC > 0.80** - ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à! ‡πÑ‡∏î‡πâ 0.8379
- [x] **Test SMOTE Resampling** - ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡πÅ‡∏•‡πâ‡∏ß! ‡πÅ‡∏ï‡πà‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏ä‡πà‡∏ß‡∏¢‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á performance (Recall ‡∏•‡∏î‡∏•‡∏á 7.5 pp.)
- [x] **Test ADASYN Resampling** - ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡πÅ‡∏•‡πâ‡∏ß! ‡πÅ‡∏¢‡πà‡∏Å‡∏ß‡πà‡∏≤ SMOTE (Recall ‡∏•‡∏î‡∏•‡∏á 8.8 pp.)
- [x] **Test SMOTETomek (Hybrid)** - ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡πÅ‡∏•‡πâ‡∏ß! Precision ‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î ‡πÅ‡∏ï‡πà Recall ‡∏¢‡∏±‡∏á‡∏ï‡πà‡∏≥ (‡∏•‡∏î‡∏•‡∏á 8.5 pp.)
- [x] **Test Cost-Sensitive Learning** - ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à! Recall ‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î (91.83%) ‡πÅ‡∏ï‡πà Precision ‡∏ï‡πà‡∏≥ (28.38%)

**üìä ‡∏™‡∏£‡∏∏‡∏õ‡∏à‡∏≤‡∏Å‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î:**

| Method                | ROC-AUC    | Recall     | Precision  | F1         | Ranking     |
| --------------------- | ---------- | ---------- | ---------- | ---------- | ----------- |
| **Class Weights**     | **0.8379** | 0.6895     | **0.4862** | **0.5703** | ü•á **Best** |
| Cost-Sensitive (10.0) | 0.8220     | **0.9183** | 0.2838     | 0.4336     | ü•à 2nd      |
| SMOTE                 | 0.8170     | 0.6144     | 0.5123     | 0.5587     | ü•â 3rd      |
| SMOTETomek            | 0.8121     | 0.6046     | 0.5153     | 0.5564     | 4th         |
| ADASYN                | 0.8106     | 0.6013     | 0.5041     | 0.5484     | 5th         |

**üí° ‡∏Ç‡πâ‡∏≠‡∏™‡∏£‡∏∏‡∏õ:**

- ‚úÖ **Class Weights (Run #2) ‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏†‡∏≤‡∏û‡∏£‡∏ß‡∏°** - Balance, ROI ‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î
- ‚úÖ **Cost-Sensitive (Run #6) ‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Recall** - ‡∏à‡∏±‡∏ö Churn ‡πÑ‡∏î‡πâ‡∏°‡∏≤‡∏Å‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î
- ‚ùå **Synthetic Sampling ‡∏ó‡∏∏‡∏Å‡∏ß‡∏¥‡∏ò‡∏µ‡∏™‡∏£‡πâ‡∏≤‡∏á overfitting ‡πÅ‡∏•‡∏∞‡∏•‡∏î Recall**
- ‚ùå **Hybrid approach (SMOTETomek) ‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡πÅ‡∏Å‡πâ‡∏õ‡∏±‡∏ç‡∏´‡∏≤**
- ‚úÖ **‡∏Ñ‡∏ß‡∏£‡πÉ‡∏ä‡πâ Run #2 ‡πÄ‡∏õ‡πá‡∏ô default model, Run #6 ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö campaign ‡∏û‡∏¥‡πÄ‡∏®‡∏©**

---

## Next Immediate Steps

**‚úÖ All Major Experiments - COMPLETED:**

- [x] **Run #2: Class Weights** - ‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏†‡∏≤‡∏û‡∏£‡∏ß‡∏°
- [x] **Run #3: SMOTE** - ‡πÑ‡∏°‡πà‡∏î‡∏µ‡πÄ‡∏ó‡πà‡∏≤ Class Weights
- [x] **Run #4: ADASYN** - ‡πÅ‡∏¢‡πà‡∏Å‡∏ß‡πà‡∏≤ SMOTE
- [x] **Run #5: SMOTETomek** - Precision ‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î ‡πÅ‡∏ï‡πà Recall ‡∏ï‡πà‡∏≥
- [x] **Run #6: Cost-Sensitive Learning** - Recall ‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î (91.83%)!

**üìä ‡∏™‡∏£‡∏∏‡∏õ:**

- **Run #2 (Class Weights)** = Best Overall (F1, ROC-AUC, ROI)
- **Run #6 (Cost-Sensitive)** = Best Recall (91.83%)

---

**üîÑ ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ñ‡∏±‡∏î‡πÑ‡∏õ (‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥):**

1. **Threshold Tuning (Run #2)** - ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ó‡∏≥‡∏Å‡πà‡∏≠‡∏ô ‚≠ê

   - ‡∏õ‡∏£‡∏±‡∏ö threshold ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏û‡∏¥‡πà‡∏° Recall ‡πÉ‡∏´‡πâ‡∏ñ‡∏∂‡∏á 70%+
   - ‡∏´‡∏£‡∏∑‡∏≠ balance ‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á Precision & Recall
   - ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á retrain model!

2. **Hyperparameter Tuning (Run #2)**

   - Fine-tune XGBoost parameters
   - ‡∏≠‡∏≤‡∏à‡πÄ‡∏û‡∏¥‡πà‡∏° ROC-AUC ‡πÑ‡∏î‡πâ‡∏≠‡∏µ‡∏Å 1-2%

3. **Ensemble Model**

   - ‡∏£‡∏ß‡∏° Run #2 (Baseline) + Run #6 (Cost-Sensitive)
   - Best of both worlds!

4. **Deploy Model**
   - ‡∏™‡∏£‡πâ‡∏≤‡∏á API ‡∏´‡∏£‡∏∑‡∏≠ web app
   - ‡πÉ‡∏ä‡πâ Run #2 ‡πÄ‡∏õ‡πá‡∏ô default model
   - ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏° Run #6 (Cost Ratio 20.0) ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö campaign ‡∏û‡∏¥‡πÄ‡∏®‡∏©

---

**‚ùå ‡πÑ‡∏°‡πà‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥ (‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡πÅ‡∏•‡πâ‡∏ß‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏ú‡∏•):**

- ‚ùå **SMOTEENN** - ‡∏Ñ‡∏≤‡∏î‡∏ß‡πà‡∏≤‡∏à‡∏∞‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢ SMOTETomek
- ‚ùå **Focal Loss** - ‡∏ã‡∏±‡∏ö‡∏ã‡πâ‡∏≠‡∏ô‡πÅ‡∏•‡∏∞‡πÑ‡∏°‡πà‡∏Ñ‡∏∏‡πâ‡∏°‡∏Ñ‡πà‡∏≤
- ‚ùå **Synthetic Sampling ‡∏≠‡∏∑‡πà‡∏ô‡πÜ** - ‡πÑ‡∏°‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏Å‡∏±‡∏ö dataset ‡∏ô‡∏µ‡πâ (imbalance ratio 4:1)

---

## üìå Final Recommendations

**‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Production:**

1. **Default Model: Run #2 (Class Weights)**

   - ‡πÉ‡∏ä‡πâ‡πÄ‡∏õ‡πá‡∏ô default model ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ
   - Balance ‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î, ROI ‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î
   - Threshold = 0.5

2. **Special Campaign: Run #6 (Cost-Sensitive, Ratio 20.0)**
   - ‡πÉ‡∏ä‡πâ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö campaign ‡∏û‡∏¥‡πÄ‡∏®‡∏©‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏ö Churn ‡πÉ‡∏´‡πâ‡πÑ‡∏î‡πâ‡∏°‡∏≤‡∏Å‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î
   - Recall = 95.10% (‡∏û‡∏•‡∏≤‡∏î‡πÅ‡∏Ñ‡πà 15 ‡∏Ñ‡∏ô!)
   - ‡∏¢‡∏≠‡∏°‡∏£‡∏±‡∏ö False Positive ‡∏™‡∏π‡∏á

**‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ò‡∏ô‡∏≤‡∏Ñ‡∏≤‡∏£:**

- **‡∏ò‡∏ô‡∏≤‡∏Ñ‡∏≤‡∏£‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏ó‡∏£‡∏±‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏à‡∏≥‡∏Å‡∏±‡∏î** ‚Üí ‡πÉ‡∏ä‡πâ Run #2
- **‡∏ò‡∏ô‡∏≤‡∏Ñ‡∏≤‡∏£‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏ó‡∏µ‡∏° Retention ‡∏Ç‡∏ô‡∏≤‡∏î‡πÉ‡∏´‡∏ç‡πà** ‚Üí ‡πÉ‡∏ä‡πâ Run #6

---

**Last Updated:** 2026-01-16

**Total Experiments:** 6 Runs

**Best Model:** Run #2 (Class Weights) - ROC-AUC = 0.8379, F1 = 0.5703

**Highest Recall:** Run #6 (Cost-Sensitive) - Recall = 0.9183
