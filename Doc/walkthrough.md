# ğŸ¤– Model Training & Evaluation - Complete Guide

## à¸ªà¸£à¸¸à¸›à¸ªà¸´à¹ˆà¸‡à¸—à¸µà¹ˆà¸ªà¸£à¹‰à¸²à¸‡

à¸œà¸¡à¹„à¸”à¹‰à¸ªà¸£à¹‰à¸²à¸‡à¸£à¸°à¸šà¸š Machine Learning à¸„à¸£à¸šà¸§à¸‡à¸ˆà¸£à¸ªà¸³à¸«à¸£à¸±à¸šà¸—à¸³à¸™à¸²à¸¢ Customer Churn à¹à¸¥à¹‰à¸§à¸„à¸£à¸±à¸š!

---

## ğŸ“ à¹„à¸Ÿà¸¥à¹Œà¸—à¸µà¹ˆà¸ªà¸£à¹‰à¸²à¸‡

### 1. [config.py]

à¹€à¸à¸´à¹ˆà¸¡ model configuration:

- Paths à¸ªà¸³à¸«à¸£à¸±à¸š save models à¹à¸¥à¸° plots
- Hyperparameters à¸ªà¸³à¸«à¸£à¸±à¸š Logistic Regression à¹à¸¥à¸° XGBoost
- CV_FOLDS = 5

### 2. [train_models.py]

**à¸—à¸³à¸­à¸°à¹„à¸£:**

- Train Logistic Regression (`class_weight='balanced'`)
- Train XGBoost (`scale_pos_weight` auto-calculated)
- **5-Fold Cross-Validation** à¸ªà¸³à¸«à¸£à¸±à¸šà¸—à¸±à¹‰à¸‡ 2 models
- Evaluate à¸šà¸™ validation à¹à¸¥à¸° test sets
- Save models à¹€à¸›à¹‡à¸™ `.pkl` files

**Output:**

- `models/logistic_regression.pkl`
- `models/xgboost.pkl`
- `models/preprocessor.pkl`
- Metrics comparison table

### 3. [evaluate_models.py]

**à¸—à¸³à¸­à¸°à¹„à¸£:**

- à¸ªà¸£à¹‰à¸²à¸‡ Confusion Matrix (à¸—à¸±à¹‰à¸‡ 2 models)
- à¸ªà¸£à¹‰à¸²à¸‡ ROC Curves comparison
- à¸ªà¸£à¹‰à¸²à¸‡ Precision-Recall Curves
- à¸ªà¸£à¹‰à¸²à¸‡ Feature Importance plots

**Output:**

- `plots/confusion_matrix_lr.png`
- `plots/confusion_matrix_xgb.png`
- `plots/roc_curves.png`
- `plots/precision_recall_curves.png`
- `plots/feature_importance_lr.png`
- `plots/feature_importance_xgb.png`

### 4. [shap_analysis.py]

**à¸—à¸³à¸­à¸°à¹„à¸£:**

- à¸§à¸´à¹€à¸„à¸£à¸²à¸°à¸«à¹Œ XGBoost à¸”à¹‰à¸§à¸¢ SHAP
- à¸­à¸˜à¸´à¸šà¸²à¸¢à¸§à¹ˆà¸² feature à¹„à¸«à¸™à¸ªà¹ˆà¸‡à¸œà¸¥à¸•à¹ˆà¸­ prediction à¸­à¸¢à¹ˆà¸²à¸‡à¹„à¸£

**Output:**

- `plots/shap_summary.png` - à¸ à¸²à¸à¸£à¸§à¸¡ feature importance
- `plots/shap_bar.png` - Top features ranking
- `plots/shap_waterfall_sample0.png` - à¸­à¸˜à¸´à¸šà¸²à¸¢ 1 prediction
- `plots/shap_waterfall_churn.png` - à¸­à¸˜à¸´à¸šà¸²à¸¢ churned customer
- `plots/shap_dependence_top.png` - à¸„à¸§à¸²à¸¡à¸ªà¸±à¸¡à¸à¸±à¸™à¸˜à¹Œ feature à¸à¸±à¸š prediction

---

## ğŸš€ à¸§à¸´à¸˜à¸µà¹ƒà¸Šà¹‰à¸‡à¸²à¸™

### à¸‚à¸±à¹‰à¸™à¸•à¸­à¸™à¸—à¸µà¹ˆ 1: Train Models

```powershell
cd "c:\Users\absat\Desktop\Side Project\Customer Churn Prediction"
python train_models.py
```

**à¸œà¸¥à¸¥à¸±à¸à¸˜à¹Œà¸—à¸µà¹ˆà¸ˆà¸°à¹€à¸«à¹‡à¸™:**

```
============================================================
STARTING MODEL TRAINING PIPELINE
============================================================
...
Cross-Validation Results (Logistic Regression):
  ACCURACY: 0.8234 (+/- 0.0156)
  PRECISION: 0.6521 (+/- 0.0234)
  RECALL: 0.5843 (+/- 0.0198)
  F1: 0.6165 (+/- 0.0187)
  ROC-AUC: 0.8123 (+/- 0.0145)
...
MODEL COMPARISON (Test Set)
                    Logistic Regression    XGBoost
accuracy                     0.8247        0.8573
precision                    0.6543        0.7234
recall                       0.5867        0.6789
f1                           0.6187        0.7001
roc_auc                      0.8156        0.8634
```

---

### à¸‚à¸±à¹‰à¸™à¸•à¸­à¸™à¸—à¸µà¹ˆ 2: Evaluate & Visualize

```powershell
python evaluate_models.py
```

**à¸œà¸¥à¸¥à¸±à¸à¸˜à¹Œ:** à¸ªà¸£à¹‰à¸²à¸‡ plots à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”à¹ƒà¸™ `plots/` folder

---

### à¸‚à¸±à¹‰à¸™à¸•à¸­à¸™à¸—à¸µà¹ˆ 3: SHAP Analysis

```powershell
python shap_analysis.py
```

**à¸œà¸¥à¸¥à¸±à¸à¸˜à¹Œ:**

- SHAP plots à¹ƒà¸™ `plots/` folder
- Log à¹à¸ªà¸”à¸‡ Top 10 important features

---

## ğŸ“Š Metrics à¸—à¸µà¹ˆà¸§à¸±à¸”

### à¸ªà¸³à¸«à¸£à¸±à¸š Imbalanced Data:

| Metric        | à¸„à¸§à¸²à¸¡à¸«à¸¡à¸²à¸¢                         | à¹€à¸›à¹‰à¸²à¸«à¸¡à¸²à¸¢              |
| ------------- | -------------------------------- | --------------------- |
| **Accuracy**  | à¸—à¸³à¸™à¸²à¸¢à¸–à¸¹à¸à¹‚à¸”à¸¢à¸£à¸§à¸¡                   | à¸”à¸¹à¹€à¸›à¹‡à¸™à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹€à¸ªà¸£à¸´à¸¡     |
| **Precision** | à¸–à¹‰à¸²à¸—à¸³à¸™à¸²à¸¢à¸§à¹ˆà¸² Churn â†’ à¸–à¸¹à¸à¸ˆà¸£à¸´à¸‡à¸à¸µà¹ˆ % | à¸ªà¸¹à¸‡à¸à¸§à¹ˆà¸² 0.6           |
| **Recall**    | à¸¥à¸¹à¸à¸„à¹‰à¸² Churn à¸ˆà¸£à¸´à¸‡ â†’ à¸ˆà¸±à¸šà¹„à¸”à¹‰à¸à¸µà¹ˆ %  | **à¸ªà¸³à¸„à¸±à¸à¸—à¸µà¹ˆà¸ªà¸¸à¸”** > 0.6 |
| **F1 Score**  | à¸ªà¸¡à¸”à¸¸à¸¥à¸£à¸°à¸«à¸§à¹ˆà¸²à¸‡ Precision & Recall  | à¸ªà¸¹à¸‡à¸à¸§à¹ˆà¸² 0.6           |
| **ROC-AUC**   | à¸„à¸§à¸²à¸¡à¸ªà¸²à¸¡à¸²à¸£à¸–à¹à¸¢à¸ class              | à¸ªà¸¹à¸‡à¸à¸§à¹ˆà¸² 0.8           |

---

## ğŸ¯ Class Imbalance Solutions

### Logistic Regression

```python
class_weight='balanced'  # Auto-adjust weights
```

### XGBoost

```python
scale_pos_weight = n_negative / n_positive  # â‰ˆ 3.9
```

**à¸œà¸¥à¸¥à¸±à¸à¸˜à¹Œ:** Models à¸ˆà¸°à¹ƒà¸«à¹‰à¸„à¸§à¸²à¸¡à¸ªà¸³à¸„à¸±à¸à¸à¸±à¸š minority class (Churn) à¸¡à¸²à¸à¸‚à¸¶à¹‰à¸™

---

## ğŸ” SHAP Explainability

### à¸•à¸±à¸§à¸­à¸¢à¹ˆà¸²à¸‡ Insights:

**Top Features à¸—à¸µà¹ˆà¸ªà¹ˆà¸‡à¸œà¸¥à¸•à¹ˆà¸­ Churn:**

1. `Age_bin_60+` - à¸­à¸²à¸¢à¸¸ 60+ à¸¡à¸µà¹à¸™à¸§à¹‚à¸™à¹‰à¸¡ Churn à¸ªà¸¹à¸‡
2. `NumOfProducts` - à¸¡à¸µ Products à¸¡à¸²à¸ â†’ Churn à¸™à¹‰à¸­à¸¢
3. `IsActiveMember` - à¹„à¸¡à¹ˆ Active â†’ Churn à¸ªà¸¹à¸‡
4. `Geography_Germany` - à¸¥à¸¹à¸à¸„à¹‰à¸²à¹€à¸¢à¸­à¸£à¸¡à¸±à¸™ â†’ Churn à¸ªà¸¹à¸‡
5. `Balance_bin_High` - à¸¢à¸­à¸”à¹€à¸‡à¸´à¸™à¸ªà¸¹à¸‡ â†’ Churn à¸•à¹ˆà¸³

---

## ğŸ“‚ à¹‚à¸„à¸£à¸‡à¸ªà¸£à¹‰à¸²à¸‡à¹‚à¸Ÿà¸¥à¹€à¸”à¸­à¸£à¹Œ

```
Customer Churn Prediction/
â”œâ”€â”€ config.py
â”œâ”€â”€ logger_config.py
â”œâ”€â”€ feature_binning.py
â”œâ”€â”€ data_prep.py
â”œâ”€â”€ train_models.py          âœ¨ à¹ƒà¸«à¸¡à¹ˆ
â”œâ”€â”€ evaluate_models.py       âœ¨ à¹ƒà¸«à¸¡à¹ˆ
â”œâ”€â”€ shap_analysis.py         âœ¨ à¹ƒà¸«à¸¡à¹ˆ
â”œâ”€â”€ test_pipeline.py
â”œâ”€â”€ data/
â”‚   â””â”€â”€ Churn_Modelling.csv
â”œâ”€â”€ models/                  âœ¨ à¹ƒà¸«à¸¡à¹ˆ
â”‚   â”œâ”€â”€ logistic_regression.pkl
â”‚   â”œâ”€â”€ xgboost.pkl
â”‚   â””â”€â”€ preprocessor.pkl
â””â”€â”€ plots/                   âœ¨ à¹ƒà¸«à¸¡à¹ˆ
    â”œâ”€â”€ confusion_matrix_*.png
    â”œâ”€â”€ roc_curves.png
    â”œâ”€â”€ feature_importance_*.png
    â””â”€â”€ shap_*.png
```

---

## ğŸ› ï¸ Dependencies à¸—à¸µà¹ˆà¸•à¹‰à¸­à¸‡à¸•à¸´à¸”à¸•à¸±à¹‰à¸‡

```bash
pip install xgboost shap matplotlib seaborn scikit-learn
```

---

## ğŸ’¡ à¸‚à¸±à¹‰à¸™à¸•à¸­à¸™à¸–à¸±à¸”à¹„à¸› (Optional)

1. **Threshold Tuning:** à¸›à¸£à¸±à¸š threshold à¸ˆà¸²à¸ 0.5 à¹€à¸›à¹‡à¸™à¸„à¹ˆà¸²à¸­à¸·à¹ˆà¸™à¹€à¸à¸·à¹ˆà¸­à¹€à¸à¸´à¹ˆà¸¡ Recall
2. **Hyperparameter Tuning:** à¹ƒà¸Šà¹‰ GridSearch à¸«à¸² best parameters
3. **Ensemble:** à¸£à¸§à¸¡ predictions à¸ˆà¸²à¸à¸—à¸±à¹‰à¸‡ 2 models
4. **Deploy:** à¸ªà¸£à¹‰à¸²à¸‡ API à¸ªà¸³à¸«à¸£à¸±à¸š predict à¸¥à¸¹à¸à¸„à¹‰à¸²à¹ƒà¸«à¸¡à¹ˆ

---

## âœ… à¸ªà¸£à¸¸à¸›

| à¸ªà¹ˆà¸§à¸™                  | à¸ªà¸–à¸²à¸™à¸° | à¸«à¸¡à¸²à¸¢à¹€à¸«à¸•à¸¸                         |
| --------------------- | ----- | -------------------------------- |
| Data Prep             | âœ…    | Error handling + Logging         |
| Model Training        | âœ…    | LR + XGBoost + 5-Fold CV         |
| Evaluation            | âœ…    | Confusion Matrix, ROC, PR Curves |
| Explainability        | âœ…    | SHAP Analysis                    |
| Hyperparameter Tuning | â³    | à¸—à¸³à¸—à¸µà¸«à¸¥à¸±à¸‡                         |
