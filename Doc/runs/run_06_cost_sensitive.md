# Run #6 - 2026-01-11 (Cost-Sensitive Learning)

[‚Üê ‡∏Å‡∏•‡∏±‡∏ö‡πÑ‡∏õ‡∏´‡∏ô‡πâ‡∏≤‡∏™‡∏£‡∏∏‡∏õ](../RESULTS.md)

## Configuration

- **Logistic Regression:**

  - `class_weight: 'balanced'` - ‡πÉ‡∏ä‡πâ‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô Run #2
  - `max_iter: 1000`
  - `solver: 'lbfgs'`

- **XGBoost:**

  - `n_estimators: 100`
  - `max_depth: 6`
  - `learning_rate: 0.1`
  - `scale_pos_weight: 3.9088`
  - **`sample_weight`**: ‡πÉ‡∏ä‡πâ cost-sensitive learning ‚ú®
    - Not Churn (0): weight = 1.0
    - Churn (1): weight = 10.0

- **Cross-Validation:** 5-Fold (LR only - XGBoost skip CV ‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡πÉ‡∏ä‡πâ sample_weight)
- **Threshold:** 0.5 (default)

## Imbalance Handling Strategy

**‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ:** Cost-Sensitive Learning

- **Logistic Regression:** `class_weight='balanced'` (‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡πÄ‡∏î‡∏¥‡∏°)
- **XGBoost:** `sample_weight` with `cost_ratio=10.0`

**Cost-Sensitive Learning ‡∏Ñ‡∏∑‡∏≠‡∏≠‡∏∞‡πÑ‡∏£:**

- ‡∏Å‡∏≥‡∏´‡∏ô‡∏î **cost (‡∏ï‡πâ‡∏ô‡∏ó‡∏∏‡∏ô)** ‡∏ó‡∏µ‡πà‡πÅ‡∏ï‡∏Å‡∏ï‡πà‡∏≤‡∏á‡∏Å‡∏±‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö errors ‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó
- **False Negative (‡∏û‡∏•‡∏≤‡∏î Churn)** = cost ‡∏™‡∏π‡∏á (10.0)
- **False Positive (‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢ Churn ‡∏ú‡∏¥‡∏î)** = cost ‡∏ï‡πà‡∏≥ (1.0)
- Model ‡∏à‡∏∞ **focus ‡∏ó‡∏µ‡πà‡∏Å‡∏≤‡∏£‡∏•‡∏î False Negative** ‚Üí **Recall ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡∏∂‡πâ‡∏ô**

**‡∏ó‡∏≥‡πÑ‡∏°‡∏ñ‡∏∂‡∏á‡πÉ‡∏ä‡πâ Cost-Sensitive:**

- ‚úÖ ‡∏™‡∏∞‡∏ó‡πâ‡∏≠‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏ó‡∏≤‡∏á‡∏ò‡∏∏‡∏£‡∏Å‡∏¥‡∏à (‡∏û‡∏•‡∏≤‡∏î‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤ Churn = ‡∏™‡∏π‡∏ç‡πÄ‡∏™‡∏µ‡∏¢‡∏£‡∏≤‡∏¢‡πÑ‡∏î‡πâ‡∏°‡∏≤‡∏Å)
- ‚úÖ Flexible - ‡∏õ‡∏£‡∏±‡∏ö cost ratio ‡πÑ‡∏î‡πâ‡∏ï‡∏≤‡∏°‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£
- ‚úÖ ‡πÑ‡∏°‡πà‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏±‡∏á‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå (‡∏ï‡πà‡∏≤‡∏á‡∏à‡∏≤‡∏Å SMOTE)
- ‚úÖ ‡∏á‡πà‡∏≤‡∏¢‡∏Å‡∏ß‡πà‡∏≤ Focal Loss

## Results (Test Set)

| Model                        | Accuracy   | Precision  | Recall     | F1         | ROC-AUC    |
| ---------------------------- | ---------- | ---------- | ---------- | ---------- | ---------- |
| Logistic Regression          | 0.7147     | 0.3887     | 0.6961     | 0.4988     | 0.7621     |
| **XGBoost (Cost-Sensitive)** | **0.5107** | **0.2838** | **0.9183** | **0.4336** | **0.8220** |

## Cross-Validation Results

**Logistic Regression:**

- Accuracy: 0.7110 (+/- 0.0110) ‚úÖ Stable
- Precision: 0.3813 (+/- 0.0095) ‚úÖ Stable
- Recall: 0.6690 (+/- 0.0234) ‚ö†Ô∏è ‡∏ú‡∏±‡∏ô‡πÅ‡∏õ‡∏£‡πÄ‡∏•‡πá‡∏Å‡∏ô‡πâ‡∏≠‡∏¢
- F1: 0.4854 (+/- 0.0059) ‚úÖ Stable
- ROC-AUC: 0.7626 (+/- 0.0046) ‚úÖ Very Stable

**XGBoost:**

- ‚ö†Ô∏è **Skipped Cross-Validation** ‡πÄ‡∏û‡∏£‡∏≤‡∏∞ sklearn's `cross_validate` ‡πÑ‡∏°‡πà‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö `sample_weight` ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö XGBoost

## Observations & Insights

**üéØ Cost-Sensitive Learning ‡πÑ‡∏î‡πâ‡∏ú‡∏•‡∏ï‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏Ñ‡∏≤‡∏î‡∏´‡∏ß‡∏±‡∏á:**

1. **Recall ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡∏∂‡πâ‡∏ô‡∏°‡∏≤‡∏Å (91.83%)** üöÄ

   - ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏à‡∏≤‡∏Å Run #2: 68.95% ‚Üí 91.83% (+22.88 pp)
   - ‡∏à‡∏±‡∏ö‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤‡∏ó‡∏µ‡πà Churn ‡πÑ‡∏î‡πâ **281/306 ‡∏Ñ‡∏ô** (‡∏û‡∏•‡∏≤‡∏î‡πÅ‡∏Ñ‡πà 25 ‡∏Ñ‡∏ô!)
   - **‡πÄ‡∏Å‡∏¥‡∏ô‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢ 70% ‡πÑ‡∏õ‡∏ñ‡∏∂‡∏á 21.83%!**

2. **Precision ‡∏•‡∏î‡∏•‡∏á‡∏°‡∏≤‡∏Å (28.38%)**

   - ‡∏•‡∏î‡∏•‡∏á‡∏à‡∏≤‡∏Å Run #2: 48.62% ‚Üí 28.38% (-20.24 pp)
   - False Positive ‡∏™‡∏π‡∏á‡∏°‡∏≤‡∏Å: ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏ú‡∏¥‡∏î‡∏õ‡∏£‡∏∞‡∏°‡∏≤‡∏ì **710 ‡∏Ñ‡∏ô**
   - Trade-off ‡∏ó‡∏µ‡πà‡∏Ñ‡∏≤‡∏î‡∏Å‡∏≤‡∏£‡∏ì‡πå‡πÑ‡∏ß‡πâ‡πÅ‡∏•‡πâ‡∏ß

3. **ROC-AUC ‡∏¢‡∏±‡∏á‡∏Ñ‡∏á‡∏™‡∏π‡∏á (82.20%)**

   - ‡∏•‡∏î‡∏•‡∏á‡πÄ‡∏•‡πá‡∏Å‡∏ô‡πâ‡∏≠‡∏¢‡∏à‡∏≤‡∏Å Run #2: 83.79% ‚Üí 82.20% (-1.59 pp)
   - ‡∏¢‡∏±‡∏á‡∏Ñ‡∏á‡πÄ‡∏Å‡∏¥‡∏ô‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢ 80%
   - Model ‡∏¢‡∏±‡∏á‡πÅ‡∏¢‡∏Å class ‡πÑ‡∏î‡πâ‡∏î‡∏µ

4. **Accuracy ‡∏ï‡πà‡∏≥ (51.07%)**
   - ‡πÅ‡∏¢‡πà‡∏Å‡∏ß‡πà‡∏≤‡∏Å‡∏≤‡∏£‡∏ó‡∏≤‡∏¢‡∏™‡∏∏‡πà‡∏° (50%)
   - ‡πÄ‡∏û‡∏£‡∏≤‡∏∞ model bias ‡πÑ‡∏õ‡∏ó‡∏≤‡∏á Churn ‡∏°‡∏≤‡∏Å‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ

## Cost Ratio Experiment

‡∏ó‡∏î‡∏™‡∏≠‡∏ö cost ratios ‡∏ï‡πà‡∏≤‡∏á‡πÜ (5, 10, 15, 20, 25) ‡∏û‡∏ö‡∏ß‡πà‡∏≤:

| Cost Ratio         | Accuracy   | Precision  | Recall     | F1         | ROC-AUC    |
| ------------------ | ---------- | ---------- | ---------- | ---------- | ---------- |
| **0.0 (Baseline)** | **78.80%** | **48.62%** | 68.95%     | **57.03%** | **83.79%** |
| 5.0                | 58.87%     | 31.94%     | 89.87%     | 47.13%     | 83.18%     |
| 10.0               | 51.07%     | 28.38%     | 91.83%     | 43.36%     | 82.20%     |
| 15.0               | 46.73%     | 26.81%     | 93.14%     | 41.64%     | 81.99%     |
| **20.0**           | 44.60%     | 26.29%     | **95.10%** | 41.19%     | 82.34%     |
| 25.0               | 42.60%     | 25.38%     | 93.46%     | 39.92%     | 81.57%     |

**Key Findings:**

- ‚úÖ **Cost Ratio 20.0 ‡πÉ‡∏´‡πâ Recall ‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î (95.10%)**
- ‚úÖ **Baseline (Class Weights) ‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡πÉ‡∏ô‡πÄ‡∏Å‡∏∑‡∏≠‡∏ö‡∏ó‡∏∏‡∏Å metric**
- ‚ö†Ô∏è ‡∏¢‡∏¥‡πà‡∏á Cost Ratio ‡∏™‡∏π‡∏á ‚Üí Recall ‡πÄ‡∏û‡∏¥‡πà‡∏°, Precision ‡∏•‡∏î

## Business Impact Analysis

**Scenario: Cost-Sensitive (Cost Ratio = 10.0)**

**Performance:**

- Recall = 0.9183 ‚Üí ‡∏à‡∏±‡∏ö Churn ‡πÑ‡∏î‡πâ **281 ‡∏Ñ‡∏ô** (‡∏à‡∏≤‡∏Å 306 ‡∏Ñ‡∏ô)
- Precision = 0.2838 ‚Üí ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏ß‡πà‡∏≤ Churn **991 ‡∏Ñ‡∏ô** (281 ‡∏ñ‡∏π‡∏Å + 710 ‡∏ú‡∏¥‡∏î)

**‡∏ï‡πâ‡∏ô‡∏ó‡∏∏‡∏ô Retention Campaign:**

- ‡∏ï‡∏¥‡∏î‡∏ï‡πà‡∏≠‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤: 991 ‡∏Ñ‡∏ô √ó 500 ‡∏ö‡∏≤‡∏ó = **495,500 ‡∏ö‡∏≤‡∏ó**

**‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå:**

- ‡∏£‡∏±‡∏Å‡∏©‡∏≤‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤‡πÑ‡∏ß‡πâ‡πÑ‡∏î‡πâ: 281 √ó 30% = **84 ‡∏Ñ‡∏ô**
- ‡∏°‡∏π‡∏•‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡∏£‡∏±‡∏Å‡∏©‡∏≤‡πÑ‡∏ß‡πâ‡πÑ‡∏î‡πâ: 84 √ó 100,000 = **8,400,000 ‡∏ö‡∏≤‡∏ó**
- ‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤ Churn ‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏•‡∏∑‡∏≠: 306 - 84 = **222 ‡∏Ñ‡∏ô**
- ‡∏Å‡∏≤‡∏£‡∏™‡∏π‡∏ç‡πÄ‡∏™‡∏µ‡∏¢‡∏à‡∏≤‡∏Å Churn: 222 √ó 100,000 = **22,200,000 ‡∏ö‡∏≤‡∏ó**

**‡∏™‡∏£‡∏∏‡∏õ:**

- ‡∏ï‡πâ‡∏ô‡∏ó‡∏∏‡∏ô‡∏£‡∏ß‡∏°: 495,500 ‡∏ö‡∏≤‡∏ó
- ‡∏£‡∏≤‡∏¢‡πÑ‡∏î‡πâ‡∏ó‡∏µ‡πà‡∏£‡∏±‡∏Å‡∏©‡∏≤‡πÑ‡∏ß‡πâ‡πÑ‡∏î‡πâ: 8,400,000 ‡∏ö‡∏≤‡∏ó
- ‡∏Å‡∏≤‡∏£‡∏™‡∏π‡∏ç‡πÄ‡∏™‡∏µ‡∏¢‡∏à‡∏≤‡∏Å Churn: 22,200,000 ‡∏ö‡∏≤‡∏ó
- **Net Loss: 14,295,500 ‡∏ö‡∏≤‡∏ó**
- **‡∏õ‡∏£‡∏∞‡∏´‡∏¢‡∏±‡∏î‡πÑ‡∏î‡πâ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏Å‡∏±‡∏ö‡πÑ‡∏°‡πà‡∏ó‡∏≥‡∏≠‡∏∞‡πÑ‡∏£: 16,304,500 ‡∏ö‡∏≤‡∏ó** ‚úÖ
- **‡∏õ‡∏£‡∏∞‡∏´‡∏¢‡∏±‡∏î‡πÑ‡∏î‡πâ‡∏°‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤ Run #2: +3,758,000 ‡∏ö‡∏≤‡∏ó** üéâ

**ROI:**

- ROI = (16,304,500 - 495,500) / 495,500 √ó 100% = **3,192%** üöÄ

**‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏Å‡∏±‡∏ö Run #2:**

| Scenario                         | Recall | Precision | ‡∏ï‡∏¥‡∏î‡∏ï‡πà‡∏≠ (‡∏Ñ‡∏ô) | ‡∏ï‡πâ‡∏ô‡∏ó‡∏∏‡∏ô (‡∏ö‡∏≤‡∏ó) | ‡∏£‡∏±‡∏Å‡∏©‡∏≤‡πÑ‡∏î‡πâ (‡∏Ñ‡∏ô) | Net Loss (‡∏ö‡∏≤‡∏ó) | ‡∏õ‡∏£‡∏∞‡∏´‡∏¢‡∏±‡∏î‡πÑ‡∏î‡πâ (‡∏ö‡∏≤‡∏ó)  |
| -------------------------------- | ------ | --------- | ----------- | ------------ | ------------- | -------------- | ----------------- |
| **Run #2 (Class Weights)**       | 68.95% | 48.62%    | 507         | 253,500      | 64            | 18,053,500     | 12,546,500        |
| **Run #6 (Cost-Sensitive 10.0)** | 91.83% | 28.38%    | 991         | 495,500      | 84            | 14,295,500     | **16,304,500** ‚úÖ |
| **Run #6 (Cost-Sensitive 20.0)** | 95.10% | 26.29%    | 1,107       | 553,500      | 87            | 13,453,500     | **17,146,500** üèÜ |

**üèÜ Winner: Cost Ratio = 20.0**

- ‡∏õ‡∏£‡∏∞‡∏´‡∏¢‡∏±‡∏î‡πÑ‡∏î‡πâ‡∏°‡∏≤‡∏Å‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î: **17.15 ‡∏•‡πâ‡∏≤‡∏ô‡∏ö‡∏≤‡∏ó**
- Recall ‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î: **95.10%** (‡∏û‡∏•‡∏≤‡∏î‡πÅ‡∏Ñ‡πà 15 ‡∏Ñ‡∏ô!)
- ‡πÅ‡∏ï‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏ï‡∏¥‡∏î‡∏ï‡πà‡∏≠‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤ 1,107 ‡∏Ñ‡∏ô

## Next Steps & Recommendations

**‚úÖ ‡∏Ç‡πâ‡∏≠‡∏™‡∏£‡∏∏‡∏õ:**

1. **Cost-Sensitive Learning ‡πÑ‡∏î‡πâ‡∏ú‡∏•‡∏î‡∏µ‡∏°‡∏≤‡∏Å!**

   - Recall ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡∏∂‡πâ‡∏ô 22.88 pp (‡∏à‡∏≤‡∏Å 68.95% ‚Üí 91.83%)
   - ‡∏õ‡∏£‡∏∞‡∏´‡∏¢‡∏±‡∏î‡πÑ‡∏î‡πâ‡∏°‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤ Baseline 3.76 ‡∏•‡πâ‡∏≤‡∏ô‡∏ö‡∏≤‡∏ó

2. **‡πÅ‡∏ï‡πà Baseline (Run #2) ‡∏¢‡∏±‡∏á‡∏Ñ‡∏á‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏†‡∏≤‡∏û‡∏£‡∏ß‡∏°:**

   - F1 Score ‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î (57.03%)
   - ROC-AUC ‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î (83.79%)
   - ROI ‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î (5,668%)
   - Balance ‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á Precision & Recall ‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î

3. **Cost-Sensitive ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏Å‡∏±‡∏ö:**

   - ‚úÖ ‡∏ò‡∏ô‡∏≤‡∏Ñ‡∏≤‡∏£‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏ó‡∏µ‡∏° Retention ‡∏Ç‡∏ô‡∏≤‡∏î‡πÉ‡∏´‡∏ç‡πà
   - ‚úÖ ‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£ Recall ‡∏™‡∏π‡∏á‡∏°‡∏≤‡∏Å (‡∏à‡∏±‡∏ö Churn ‡πÉ‡∏´‡πâ‡πÑ‡∏î‡πâ‡∏°‡∏≤‡∏Å‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î)
   - ‚úÖ ‡∏¢‡∏≠‡∏°‡∏£‡∏±‡∏ö False Positive ‡∏™‡∏π‡∏á (‡∏ï‡∏¥‡∏î‡∏ï‡πà‡∏≠‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤‡∏ú‡∏¥‡∏î‡∏Ñ‡∏ô‡πÑ‡∏î‡πâ)

4. **Baseline ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏Å‡∏±‡∏ö:**
   - ‚úÖ ‡∏ò‡∏ô‡∏≤‡∏Ñ‡∏≤‡∏£‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏ó‡∏£‡∏±‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏à‡∏≥‡∏Å‡∏±‡∏î
   - ‚úÖ ‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£ Balance ‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á Precision & Recall
   - ‚úÖ ‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£ ROI ‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î

**üéØ ‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥:**

**‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Production:**

- ‡πÉ‡∏ä‡πâ **Baseline (Run #2)** ‡πÄ‡∏õ‡πá‡∏ô default model
- ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏° **Cost-Sensitive (Ratio 20.0)** ‡πÑ‡∏ß‡πâ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö campaign ‡∏û‡∏¥‡πÄ‡∏®‡∏©

**‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°:**

1. **Threshold Tuning ‡∏ö‡∏ô Baseline** - ‡πÄ‡∏û‡∏¥‡πà‡∏° Recall ‡πÇ‡∏î‡∏¢‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á retrain
2. **Ensemble** - ‡∏£‡∏ß‡∏° Baseline + Cost-Sensitive
3. **Hyperparameter Tuning** - Fine-tune XGBoost parameters

## Plots

**All visualizations saved in:** `plots/run_6/`

- ‚úÖ `confusion_matrix_lr.png` - Confusion Matrix (Logistic Regression)
- ‚úÖ `confusion_matrix_xgb.png` - Confusion Matrix (XGBoost)
- ‚úÖ `roc_curves.png` - ROC Curves
- ‚úÖ `precision_recall_curves.png` - Precision-Recall Curves
- ‚úÖ `feature_importance_lr.png` - Feature Importance (Logistic Regression)
- ‚úÖ `feature_importance_xgb.png` - Feature Importance (XGBoost)
- ‚úÖ `shap_summary.png` - SHAP Summary Plot
- ‚úÖ `shap_bar.png` - SHAP Feature Importance
- ‚úÖ `shap_waterfall_sample0.png` - SHAP Waterfall (Sample 0)
- ‚úÖ `shap_waterfall_churn.png` - SHAP Waterfall (Churned Customer)
- ‚úÖ `shap_dependence_top.png` - SHAP Dependence Plot

**Cost Ratio Experiment:**

- ‚úÖ `experiments/run_6_cost_sensitive/cost_ratio_comparison.csv`
- ‚úÖ `experiments/run_6_cost_sensitive/cost_ratio_comparison.png`

---

[‚Üê ‡∏Å‡∏•‡∏±‡∏ö‡πÑ‡∏õ‡∏´‡∏ô‡πâ‡∏≤‡∏™‡∏£‡∏∏‡∏õ](../RESULTS.md)
